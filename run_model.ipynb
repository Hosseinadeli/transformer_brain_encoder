{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/engram/nklab/hossein/recurrent_models/transformer_brain_encoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#switch to the directory where the code is\n",
    "os.chdir('/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "lh_challenge_rois_s.shape: torch.Size([24, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([24, 20544])\n",
      "lh_challenge_rois_0.sum: tensor(5350, device='cuda:0')\n",
      "lh_challenge_rois_s.shape: torch.Size([25, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([25, 20544])\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Number of model parameters: 36805564\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(50, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:05:39  lr: 0.000500  loss_labels: 1.8509 (1.8509)  loss: 1.8509 (1.8509)  time: 1.2240\n",
      "Epoch: [0]  [100/277]  eta: 0:01:04  lr: 0.000500  loss_labels: 0.9540 (0.9883)  loss: 0.9046 (0.9883)  time: 0.3620\n",
      "Epoch: [0]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.8600 (0.9291)  loss: 0.8495 (0.9291)  time: 0.3610\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8324 (0.9023)  loss: 0.8353 (0.9023)  time: 0.3502\n",
      "Epoch: [0] Total time: 0:01:39 (0.3590 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8324 (0.9023)  loss: 0.8353 (0.9023)\n",
      "Test:  [ 0/31]  eta: 0:00:11  loss_labels: 0.8613 (0.8613)  loss: 0.8613 (0.8613)  time: 0.3682\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7856 (0.7862)  loss: 0.7670 (0.7862)  time: 0.3533\n",
      "Test: Total time: 0:00:10 (0.3538 s / it)\n",
      "Averaged stats: loss_labels: 0.7856 (0.7862)  loss: 0.7670 (0.7862)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1591.59it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1593.40it/s]\n",
      "val_perf: 0.4298275502066601\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [1]  [  0/277]  eta: 0:01:39  lr: 0.000500  loss_labels: 0.8285 (0.8285)  loss: 0.8285 (0.8285)  time: 0.3584\n",
      "Epoch: [1]  [100/277]  eta: 0:01:04  lr: 0.000500  loss_labels: 0.7947 (0.7994)  loss: 0.7805 (0.7994)  time: 0.3510\n",
      "Epoch: [1]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.7886 (0.7982)  loss: 0.7820 (0.7982)  time: 0.3540\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.7699 (0.7911)  loss: 0.7630 (0.7911)  time: 0.3483\n",
      "Epoch: [1] Total time: 0:01:38 (0.3565 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.7699 (0.7911)  loss: 0.7630 (0.7911)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.8247 (0.8247)  loss: 0.8247 (0.8247)  time: 0.3500\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7543 (0.7565)  loss: 0.7494 (0.7565)  time: 0.3556\n",
      "Test: Total time: 0:00:10 (0.3531 s / it)\n",
      "Averaged stats: loss_labels: 0.7543 (0.7565)  loss: 0.7494 (0.7565)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1591.77it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1602.75it/s]\n",
      "val_perf: 0.4534961461623628\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.19it/s]\n",
      "Epoch: [2]  [  0/277]  eta: 0:01:47  lr: 0.000500  loss_labels: 0.7970 (0.7970)  loss: 0.7970 (0.7970)  time: 0.3887\n",
      "Epoch: [2]  [100/277]  eta: 0:01:02  lr: 0.000500  loss_labels: 0.7596 (0.7618)  loss: 0.7603 (0.7618)  time: 0.3538\n",
      "Epoch: [2]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.7559 (0.7631)  loss: 0.7835 (0.7631)  time: 0.3524\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.7507 (0.7591)  loss: 0.7577 (0.7591)  time: 0.3507\n",
      "Epoch: [2] Total time: 0:01:38 (0.3538 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.7507 (0.7591)  loss: 0.7577 (0.7591)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.8059 (0.8059)  loss: 0.8059 (0.8059)  time: 0.3507\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7408 (0.7440)  loss: 0.7213 (0.7440)  time: 0.3427\n",
      "Test: Total time: 0:00:10 (0.3450 s / it)\n",
      "Averaged stats: loss_labels: 0.7408 (0.7440)  loss: 0.7213 (0.7440)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1588.23it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1600.89it/s]\n",
      "val_perf: 0.4626604151385909\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [3]  [  0/277]  eta: 0:01:38  lr: 0.000250  loss_labels: 0.7499 (0.7499)  loss: 0.7499 (0.7499)  time: 0.3555\n",
      "Epoch: [3]  [100/277]  eta: 0:01:03  lr: 0.000250  loss_labels: 0.7226 (0.7297)  loss: 0.7393 (0.7297)  time: 0.3526\n",
      "Epoch: [3]  [200/277]  eta: 0:00:27  lr: 0.000250  loss_labels: 0.7197 (0.7277)  loss: 0.7151 (0.7277)  time: 0.3526\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7281 (0.7301)  loss: 0.7200 (0.7301)  time: 0.3481\n",
      "Epoch: [3] Total time: 0:01:38 (0.3555 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7281 (0.7301)  loss: 0.7200 (0.7301)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.7876 (0.7876)  loss: 0.7876 (0.7876)  time: 0.3485\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7296 (0.7285)  loss: 0.7149 (0.7285)  time: 0.3398\n",
      "Test: Total time: 0:00:10 (0.3423 s / it)\n",
      "Averaged stats: loss_labels: 0.7296 (0.7285)  loss: 0.7149 (0.7285)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1589.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1594.89it/s]\n",
      "val_perf: 0.47326889614027834\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.90it/s]\n",
      "Epoch: [4]  [  0/277]  eta: 0:01:36  lr: 0.000250  loss_labels: 0.7222 (0.7222)  loss: 0.7222 (0.7222)  time: 0.3487\n",
      "Epoch: [4]  [100/277]  eta: 0:01:02  lr: 0.000250  loss_labels: 0.7159 (0.7187)  loss: 0.7159 (0.7187)  time: 0.3525\n",
      "Epoch: [4]  [200/277]  eta: 0:00:27  lr: 0.000250  loss_labels: 0.7207 (0.7206)  loss: 0.7000 (0.7206)  time: 0.3504\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7115 (0.7195)  loss: 0.7059 (0.7195)  time: 0.3490\n",
      "Epoch: [4] Total time: 0:01:37 (0.3535 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7115 (0.7195)  loss: 0.7059 (0.7195)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.7896 (0.7896)  loss: 0.7896 (0.7896)  time: 0.3518\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7305 (0.7270)  loss: 0.7056 (0.7270)  time: 0.3422\n",
      "Test: Total time: 0:00:10 (0.3441 s / it)\n",
      "Averaged stats: loss_labels: 0.7305 (0.7270)  loss: 0.7056 (0.7270)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1587.32it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1596.28it/s]\n",
      "val_perf: 0.4753970129382543\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [5]  [  0/277]  eta: 0:01:37  lr: 0.000250  loss_labels: 0.6251 (0.6251)  loss: 0.6251 (0.6251)  time: 0.3534\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 534, in <module>\n",
      "    main(0, 1, args)\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 430, in main\n",
      "    train_stats = train_one_epoch(\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/engine.py\", line 24, in train_one_epoch\n",
      "    for imgs, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/utils/utils.py\", line 240, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/datasets/nsd.py\", line 80, in __getitem__\n",
      "    img = Image.open(img_path).convert('RGB')\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/Image.py\", line 916, in convert\n",
      "    self.load()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/ImageFile.py\", line 216, in load\n",
      "    self.load_prepare()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/PngImagePlugin.py\", line 919, in load_prepare\n",
      "    ImageFile.ImageFile.load_prepare(self)\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/ImageFile.py\", line 295, in load_prepare\n",
      "    self.im = Image.core.new(self.mode, self.size)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --run 15 --image_size 224 --epochs 10 --readout_res 'rois_all' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 #--pre_norm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "lh_challenge_rois_s.shape: torch.Size([24, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([24, 20544])\n",
      "lh_challenge_rois_0.sum: tensor(5350, device='cuda:0')\n",
      "lh_challenge_rois_s.shape: torch.Size([25, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([25, 20544])\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n",
      "d_model: 768 nhead: 16\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Number of model parameters: 36213436\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (cross_attn): CrossAttention(\n",
      "            (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(50, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.cross_attn.c_attn.weight', 'transformer.decoder.layers.0.cross_attn.c_attn.bias', 'transformer.decoder.layers.0.cross_attn.k_proj.weight', 'transformer.decoder.layers.0.cross_attn.k_proj.bias', 'transformer.decoder.layers.0.cross_attn.q_proj.weight', 'transformer.decoder.layers.0.cross_attn.q_proj.bias', 'transformer.decoder.layers.0.cross_attn.v_proj.weight', 'transformer.decoder.layers.0.cross_attn.v_proj.bias', 'transformer.decoder.layers.0.cross_attn.c_proj.weight', 'transformer.decoder.layers.0.cross_attn.c_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhosseinadeli\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/wandb/run-20241116_111342-nuajzejv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msub1_no_proj_r5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/hosseinadeli/NSD_paper\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/hosseinadeli/NSD_paper/runs/nuajzejv\u001b[0m\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:06:15  lr: 0.000500  loss_labels: 2.2137 (2.2137)  loss: 2.2137 (2.2137)  time: 1.3541\n",
      "Epoch: [0]  [100/277]  eta: 0:01:34  lr: 0.000500  loss_labels: 0.9161 (0.9503)  loss: 0.8668 (0.9503)  time: 0.5245\n",
      "Epoch: [0]  [200/277]  eta: 0:00:40  lr: 0.000500  loss_labels: 0.8354 (0.8995)  loss: 0.8334 (0.8995)  time: 0.5308\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8484 (0.8866)  loss: 0.8208 (0.8866)  time: 0.5189\n",
      "Epoch: [0] Total time: 0:02:26 (0.5285 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8484 (0.8866)  loss: 0.8208 (0.8866)\n",
      "Test:  [ 0/31]  eta: 0:00:19  loss_labels: 0.8841 (0.8841)  loss: 0.8841 (0.8841)  time: 0.6208\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8246 (0.8295)  loss: 0.8162 (0.8295)  time: 0.5223\n",
      "Test: Total time: 0:00:16 (0.5246 s / it)\n",
      "Averaged stats: loss_labels: 0.8246 (0.8295)  loss: 0.8162 (0.8295)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1703.36it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1701.49it/s]\n",
      "val_perf: 0.38928752458371596\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.99it/s]\n",
      "Epoch: [1]  [  0/277]  eta: 0:02:20  lr: 0.000500  loss_labels: 0.7741 (0.7741)  loss: 0.7741 (0.7741)  time: 0.5083\n",
      "Epoch: [1]  [100/277]  eta: 0:01:31  lr: 0.000500  loss_labels: 0.8135 (0.8210)  loss: 0.7896 (0.8210)  time: 0.5098\n",
      "Epoch: [1]  [200/277]  eta: 0:00:39  lr: 0.000500  loss_labels: 0.8171 (0.8183)  loss: 0.7785 (0.8183)  time: 0.5095\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8085 (0.8161)  loss: 0.8024 (0.8161)  time: 0.5070\n",
      "Epoch: [1] Total time: 0:02:21 (0.5126 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8085 (0.8161)  loss: 0.8024 (0.8161)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8930 (0.8930)  loss: 0.8930 (0.8930)  time: 0.5018\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8088 (0.8254)  loss: 0.8072 (0.8254)  time: 0.5176\n",
      "Test: Total time: 0:00:15 (0.5129 s / it)\n",
      "Averaged stats: loss_labels: 0.8088 (0.8254)  loss: 0.8072 (0.8254)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1702.35it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1694.09it/s]\n",
      "val_perf: 0.4062537162954998\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.97it/s]\n",
      "Epoch: [2]  [  0/277]  eta: 0:02:27  lr: 0.000500  loss_labels: 0.8755 (0.8755)  loss: 0.8755 (0.8755)  time: 0.5310\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "Epoch: [2]  [100/277]  eta: 0:01:30  lr: 0.000500  loss_labels: 0.7931 (0.8015)  loss: 0.8027 (0.8015)  time: 0.5107\n",
      "Epoch: [2]  [200/277]  eta: 0:00:39  lr: 0.000500  loss_labels: 0.7932 (0.7987)  loss: 0.7729 (0.7987)  time: 0.5122\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.7897 (0.7976)  loss: 0.7809 (0.7976)  time: 0.5017\n",
      "Epoch: [2] Total time: 0:02:21 (0.5100 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.7897 (0.7976)  loss: 0.7809 (0.7976)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8691 (0.8691)  loss: 0.8691 (0.8691)  time: 0.4986\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8010 (0.8047)  loss: 0.8007 (0.8047)  time: 0.5110\n",
      "Test: Total time: 0:00:15 (0.5082 s / it)\n",
      "Averaged stats: loss_labels: 0.8010 (0.8047)  loss: 0.8007 (0.8047)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1689.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1687.20it/s]\n",
      "val_perf: 0.41763915699714127\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.93it/s]\n",
      "Epoch: [3]  [  0/277]  eta: 0:02:24  lr: 0.000250  loss_labels: 0.7884 (0.7884)  loss: 0.7884 (0.7884)  time: 0.5217\n",
      "Epoch: [3]  [100/277]  eta: 0:01:30  lr: 0.000250  loss_labels: 0.7630 (0.7753)  loss: 0.7557 (0.7753)  time: 0.5101\n",
      "Epoch: [3]  [200/277]  eta: 0:00:39  lr: 0.000250  loss_labels: 0.7682 (0.7733)  loss: 0.7677 (0.7733)  time: 0.5107\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7711 (0.7745)  loss: 0.7896 (0.7745)  time: 0.5042\n",
      "Epoch: [3] Total time: 0:02:22 (0.5151 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7711 (0.7745)  loss: 0.7896 (0.7745)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8442 (0.8442)  loss: 0.8442 (0.8442)  time: 0.5004\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7868 (0.7916)  loss: 0.7784 (0.7916)  time: 0.5158\n",
      "Test: Total time: 0:00:15 (0.5102 s / it)\n",
      "Averaged stats: loss_labels: 0.7868 (0.7916)  loss: 0.7784 (0.7916)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1695.42it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1695.85it/s]\n",
      "val_perf: 0.4224447404602113\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  1.86it/s]\n",
      "Epoch: [4]  [  0/277]  eta: 0:02:27  lr: 0.000250  loss_labels: 0.7655 (0.7655)  loss: 0.7655 (0.7655)  time: 0.5328\n",
      "Epoch: [4]  [100/277]  eta: 0:01:30  lr: 0.000250  loss_labels: 0.7585 (0.7644)  loss: 0.7595 (0.7644)  time: 0.5127\n",
      "Epoch: [4]  [200/277]  eta: 0:00:39  lr: 0.000250  loss_labels: 0.7508 (0.7642)  loss: 0.7584 (0.7642)  time: 0.5149\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7641 (0.7657)  loss: 0.7641 (0.7657)  time: 0.5077\n",
      "Epoch: [4] Total time: 0:02:22 (0.5131 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7641 (0.7657)  loss: 0.7641 (0.7657)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8414 (0.8414)  loss: 0.8414 (0.8414)  time: 0.5069\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7835 (0.7882)  loss: 0.7771 (0.7882)  time: 0.5139\n",
      "Test: Total time: 0:00:15 (0.5106 s / it)\n",
      "Averaged stats: loss_labels: 0.7835 (0.7882)  loss: 0.7771 (0.7882)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1695.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1693.84it/s]\n",
      "val_perf: 0.4262675595766249\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.00it/s]\n",
      "Epoch: [5]  [  0/277]  eta: 0:02:17  lr: 0.000250  loss_labels: 0.7575 (0.7575)  loss: 0.7575 (0.7575)  time: 0.4949\n",
      "Epoch: [5]  [100/277]  eta: 0:01:31  lr: 0.000250  loss_labels: 0.7522 (0.7547)  loss: 0.7428 (0.7547)  time: 0.5108\n",
      "Epoch: [5]  [200/277]  eta: 0:00:39  lr: 0.000250  loss_labels: 0.7566 (0.7602)  loss: 0.7571 (0.7602)  time: 0.5092\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7519 (0.7584)  loss: 0.7352 (0.7584)  time: 0.5074\n",
      "Epoch: [5] Total time: 0:02:22 (0.5145 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7519 (0.7584)  loss: 0.7352 (0.7584)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.8502 (0.8502)  loss: 0.8502 (0.8502)  time: 0.6029\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7962 (0.7918)  loss: 0.7862 (0.7918)  time: 0.5469\n",
      "Test: Total time: 0:00:17 (0.5797 s / it)\n",
      "Averaged stats: loss_labels: 0.7962 (0.7918)  loss: 0.7862 (0.7918)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1690.45it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1697.49it/s]\n",
      "val_perf: 0.4247506035048392\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [6]  [  0/277]  eta: 0:02:26  lr: 0.000125  loss_labels: 0.7985 (0.7985)  loss: 0.7985 (0.7985)  time: 0.5295\n",
      "Epoch: [6]  [100/277]  eta: 0:01:30  lr: 0.000125  loss_labels: 0.7315 (0.7363)  loss: 0.7258 (0.7363)  time: 0.5110\n",
      "Epoch: [6]  [200/277]  eta: 0:00:40  lr: 0.000125  loss_labels: 0.7225 (0.7352)  loss: 0.7024 (0.7352)  time: 0.5108\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7437 (0.7399)  loss: 0.7197 (0.7399)  time: 0.5046\n",
      "Epoch: [6] Total time: 0:02:24 (0.5212 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7437 (0.7399)  loss: 0.7197 (0.7399)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8374 (0.8374)  loss: 0.8374 (0.8374)  time: 0.5081\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7917 (0.7888)  loss: 0.7739 (0.7888)  time: 0.5308\n",
      "Test: Total time: 0:00:16 (0.5206 s / it)\n",
      "Averaged stats: loss_labels: 0.7917 (0.7888)  loss: 0.7739 (0.7888)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1699.80it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1697.12it/s]\n",
      "val_perf: 0.4247250356326986\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [7]  [  0/277]  eta: 0:02:21  lr: 0.000125  loss_labels: 0.7685 (0.7685)  loss: 0.7685 (0.7685)  time: 0.5097\n",
      "Epoch: [7]  [100/277]  eta: 0:01:30  lr: 0.000125  loss_labels: 0.7276 (0.7347)  loss: 0.7288 (0.7347)  time: 0.5224\n",
      "Epoch: [7]  [200/277]  eta: 0:00:39  lr: 0.000125  loss_labels: 0.7290 (0.7339)  loss: 0.7233 (0.7339)  time: 0.5090\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7230 (0.7323)  loss: 0.7159 (0.7323)  time: 0.5195\n",
      "Epoch: [7] Total time: 0:02:22 (0.5138 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7230 (0.7323)  loss: 0.7159 (0.7323)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8328 (0.8328)  loss: 0.8328 (0.8328)  time: 0.5008\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7855 (0.7916)  loss: 0.7795 (0.7916)  time: 0.5114\n",
      "Test: Total time: 0:00:15 (0.5102 s / it)\n",
      "Averaged stats: loss_labels: 0.7855 (0.7916)  loss: 0.7795 (0.7916)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1694.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1697.02it/s]\n",
      "val_perf: 0.42389665116742165\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [8]  [  0/277]  eta: 0:02:19  lr: 0.000125  loss_labels: 0.7449 (0.7449)  loss: 0.7449 (0.7449)  time: 0.5020\n",
      "Epoch: [8]  [100/277]  eta: 0:01:30  lr: 0.000125  loss_labels: 0.7193 (0.7234)  loss: 0.7066 (0.7234)  time: 0.5151\n",
      "Epoch: [8]  [200/277]  eta: 0:00:39  lr: 0.000125  loss_labels: 0.7172 (0.7247)  loss: 0.7107 (0.7247)  time: 0.5117\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7181 (0.7257)  loss: 0.7142 (0.7257)  time: 0.5050\n",
      "Epoch: [8] Total time: 0:02:21 (0.5121 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7181 (0.7257)  loss: 0.7142 (0.7257)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8374 (0.8374)  loss: 0.8374 (0.8374)  time: 0.5109\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7915 (0.7878)  loss: 0.7726 (0.7878)  time: 0.5169\n",
      "Test: Total time: 0:00:15 (0.5131 s / it)\n",
      "Averaged stats: loss_labels: 0.7915 (0.7878)  loss: 0.7726 (0.7878)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1691.51it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1684.54it/s]\n",
      "val_perf: 0.4256674557329404\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [9]  [  0/277]  eta: 0:02:20  lr: 0.000063  loss_labels: 0.6284 (0.6284)  loss: 0.6284 (0.6284)  time: 0.5060\n",
      "Epoch: [9]  [100/277]  eta: 0:01:30  lr: 0.000063  loss_labels: 0.7103 (0.7119)  loss: 0.7135 (0.7119)  time: 0.5169\n",
      "Epoch: [9]  [200/277]  eta: 0:00:39  lr: 0.000063  loss_labels: 0.7146 (0.7124)  loss: 0.7210 (0.7124)  time: 0.5094\n",
      "Epoch: [9]  [276/277]  eta: 0:00:00  lr: 0.000063  loss_labels: 0.7035 (0.7114)  loss: 0.7168 (0.7114)  time: 0.5118\n",
      "Epoch: [9] Total time: 0:02:21 (0.5121 s / it)\n",
      "Averaged stats: lr: 0.000063  loss_labels: 0.7035 (0.7114)  loss: 0.7168 (0.7114)\n",
      "Test:  [ 0/31]  eta: 0:00:15  loss_labels: 0.8288 (0.8288)  loss: 0.8288 (0.8288)  time: 0.4999\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7965 (0.7937)  loss: 0.7767 (0.7937)  time: 0.5079\n",
      "Test: Total time: 0:00:15 (0.5055 s / it)\n",
      "Averaged stats: loss_labels: 0.7965 (0.7937)  loss: 0.7767 (0.7937)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1685.14it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1690.77it/s]\n",
      "val_perf: 0.4196994276471129\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_perf ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: val_perf 0.4197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33msub1_no_proj_r5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/hosseinadeli/NSD_paper/runs/nuajzejv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20241116_111342-nuajzejv/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py --wandb_p 'NSD_paper' --wandb_r 'sub1_no_proj_r5'  --run 6  --epochs 10 --encoder_arch 'custom_transformer' --readout_res 'rois_all' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 #--pre_norm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 34, in <module>\n",
      "    import wandb\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/__init__.py\", line 26, in <module>\n",
      "    from wandb import sdk as wandb_sdk\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/sdk/__init__.py\", line 3, in <module>\n",
      "    from . import wandb_helper as helper  # noqa: F401\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/sdk/wandb_helper.py\", line 6, in <module>\n",
      "    from .lib import config_util\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/sdk/lib/config_util.py\", line 10, in <module>\n",
      "    from wandb.util import load_yaml\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/util.py\", line 53, in <module>\n",
      "    import wandb.env\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/wandb/env.py\", line 16, in <module>\n",
      "    from distutils.util import strtobool\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 982, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 925, in _find_spec\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/_distutils_hack/__init__.py\", line 97, in find_spec\n",
      "    return method()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/_distutils_hack/__init__.py\", line 108, in spec_for_distutils\n",
      "    mod = importlib.import_module('setuptools._distutils')\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/setuptools/__init__.py\", line 18, in <module>\n",
      "    from setuptools.dist import Distribution\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/setuptools/dist.py\", line 42, in <module>\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'rois_all' --encoder_arch 'linear' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=12\n",
    "#SBATCH --mem-per-cpu=16G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python extract_model_features.py\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3787152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax02\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=6G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax02\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 2 --readout_res 'rois_all' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --subj 3 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3914595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3914597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 8 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "voxel run for subject 1 for each input layer 2 through 12 (just one or 10 runs?) with dino2 backbone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3906333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3906335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3526223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax17\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --wandb_p 'NSD' --wandb_r 'sub5_t_voxel_lr0005_4_g.5' --readout_res 'voxels' --save_model 1 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 4 --run 1\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 220\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(16, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:05:03  lr: 0.000100  loss_labels: 0.0928 (0.0928)  loss: 0.0928 (0.0928)  time: 1.0958\n",
      "Epoch: [0]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0545 (0.0563)  loss: 0.0478 (0.0563)  time: 0.7328\n",
      "Epoch: [0]  [200/277]  eta: 0:00:58  lr: 0.000100  loss_labels: 0.0469 (0.0515)  loss: 0.0452 (0.0515)  time: 0.7811\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)  time: 0.7532\n",
      "Epoch: [0] Total time: 0:03:29 (0.7566 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0509 (0.0509)  loss: 0.0509 (0.0509)  time: 0.7239\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)  time: 0.7243\n",
      "Test: Total time: 0:00:22 (0.7259 s / it)\n",
      "Averaged stats: loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1708.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1699.74it/s]\n",
      "val_perf: 0.026510914900150034\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [1]  [  0/277]  eta: 0:03:20  lr: 0.000100  loss_labels: 0.0398 (0.0398)  loss: 0.0398 (0.0398)  time: 0.7248\n",
      "Epoch: [1]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0433 (0.0433)  loss: 0.0439 (0.0433)  time: 0.7287\n",
      "Epoch: [1]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0422 (0.0429)  loss: 0.0414 (0.0429)  time: 0.7600\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)  time: 0.7651\n",
      "Epoch: [1] Total time: 0:03:25 (0.7429 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0494 (0.0494)  loss: 0.0494 (0.0494)  time: 0.7202\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)  time: 0.7184\n",
      "Test: Total time: 0:00:22 (0.7189 s / it)\n",
      "Averaged stats: loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1700.64it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1703.31it/s]\n",
      "val_perf: 0.027940151321163592\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [2]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0428 (0.0428)  loss: 0.0428 (0.0428)  time: 0.7366\n",
      "Epoch: [2]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0408 (0.0411)  loss: 0.0399 (0.0411)  time: 0.7268\n",
      "Epoch: [2]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0409 (0.0410)  loss: 0.0418 (0.0410)  time: 0.7326\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)  time: 0.7219\n",
      "Epoch: [2] Total time: 0:03:21 (0.7289 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7253\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)  time: 0.7213\n",
      "Test: Total time: 0:00:22 (0.7190 s / it)\n",
      "Averaged stats: loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1706.20it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1705.49it/s]\n",
      "val_perf: 0.028295141922515758\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [3]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0411 (0.0411)  loss: 0.0411 (0.0411)  time: 0.7359\n",
      "Epoch: [3]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0397 (0.0400)  loss: 0.0390 (0.0400)  time: 0.7316\n",
      "Epoch: [3]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0400 (0.0402)  loss: 0.0386 (0.0402)  time: 0.7323\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)  time: 0.7214\n",
      "Epoch: [3] Total time: 0:03:21 (0.7291 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0477 (0.0477)  loss: 0.0477 (0.0477)  time: 0.7188\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)  time: 0.7194\n",
      "Test: Total time: 0:00:22 (0.7195 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1697.53it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1678.53it/s]\n",
      "val_perf: 0.028733481985735207\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.45s/it]\n",
      "Epoch: [4]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0403 (0.0403)  loss: 0.0403 (0.0403)  time: 0.7356\n",
      "Epoch: [4]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0383 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7292\n",
      "Epoch: [4]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0402 (0.0394)  loss: 0.0387 (0.0394)  time: 0.7329\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)  time: 0.7261\n",
      "Epoch: [4] Total time: 0:03:22 (0.7301 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0469 (0.0469)  loss: 0.0469 (0.0469)  time: 0.7224\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)  time: 0.7212\n",
      "Test: Total time: 0:00:22 (0.7214 s / it)\n",
      "Averaged stats: loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1693.22it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1667.95it/s]\n",
      "val_perf: 0.0287298471962317\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [5]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0380 (0.0380)  loss: 0.0380 (0.0380)  time: 0.7482\n",
      "Epoch: [5]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0384 (0.0386)  loss: 0.0384 (0.0386)  time: 0.7264\n",
      "Epoch: [5]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0391 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7300\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)  time: 0.7216\n",
      "Epoch: [5] Total time: 0:03:21 (0.7263 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0484 (0.0484)  loss: 0.0484 (0.0484)  time: 0.7292\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)  time: 0.7210\n",
      "Test: Total time: 0:00:22 (0.7223 s / it)\n",
      "Averaged stats: loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1660.93it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1636.83it/s]\n",
      "val_perf: 0.028914884954650347\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [6]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0430 (0.0430)  loss: 0.0430 (0.0430)  time: 0.7356\n",
      "Epoch: [6]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0385 (0.0384)  loss: 0.0387 (0.0384)  time: 0.7294\n",
      "Epoch: [6]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0382 (0.0385)  loss: 0.0383 (0.0385)  time: 0.7574\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)  time: 0.7231\n",
      "Epoch: [6] Total time: 0:03:22 (0.7297 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0486 (0.0486)  loss: 0.0486 (0.0486)  time: 0.7201\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)  time: 0.7155\n",
      "Test: Total time: 0:00:22 (0.7153 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1691.45it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1696.56it/s]\n",
      "val_perf: 0.028816883728600057\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [7]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0407 (0.0407)  loss: 0.0407 (0.0407)  time: 0.7388\n",
      "Epoch: [7]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0375 (0.0379)  loss: 0.0375 (0.0379)  time: 0.7286\n",
      "Epoch: [7]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0374 (0.0378)  loss: 0.0364 (0.0378)  time: 0.7292\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)  time: 0.7200\n",
      "Epoch: [7] Total time: 0:03:21 (0.7270 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7259\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)  time: 0.7174\n",
      "Test: Total time: 0:00:22 (0.7167 s / it)\n",
      "Averaged stats: loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1678.18it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1681.64it/s]\n",
      "val_perf: 0.028947353625941807\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [8]  [  0/277]  eta: 0:03:19  lr: 0.000100  loss_labels: 0.0375 (0.0375)  loss: 0.0375 (0.0375)  time: 0.7220\n",
      "Epoch: [8]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0368 (0.0372)  loss: 0.0362 (0.0372)  time: 0.7327\n",
      "Epoch: [8]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0369 (0.0372)  loss: 0.0365 (0.0372)  time: 0.7341\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)  time: 0.7262\n",
      "Epoch: [8] Total time: 0:03:22 (0.7327 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0473 (0.0473)  loss: 0.0473 (0.0473)  time: 0.7194\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)  time: 0.7182\n",
      "Test: Total time: 0:00:22 (0.7200 s / it)\n",
      "Averaged stats: loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19004/19004 [00:11<00:00, 1682.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20544/20544 [00:12<00:00, 1683.11it/s]\n",
      "val_perf: 0.028896020936347716\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [9]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0397 (0.0397)  loss: 0.0397 (0.0397)  time: 0.7493\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 473, in <module>\n",
      "    main(0, 1, args)\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 373, in main\n",
      "    train_stats = train_one_epoch(\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/engine.py\", line 24, in train_one_epoch\n",
      "    for imgs, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/utils/utils.py\", line 240, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/datasets/nsd.py\", line 83, in __getitem__\n",
      "    img = self.transform(img)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "          ^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 166, in to_tensor\n",
      "    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 701, in __array_interface__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 771, in tobytes\n",
      "    l, s, d = e.encode(bufsize)\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'faces' --save_model 1 --enc_output_layer 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39]",
   "language": "python",
   "name": "conda-env-.conda-py39-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
