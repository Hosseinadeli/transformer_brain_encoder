{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/engram/nklab/hossein/recurrent_models/transformer_brain_encoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#switch to the directory where the code is\n",
    "os.chdir('/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 220\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(16, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:04:49  lr: 0.000100  loss_labels: 1.6155 (1.6155)  loss: 1.6155 (1.6155)  time: 1.0454\n",
      "Epoch: [0]  [100/277]  eta: 0:02:05  lr: 0.000100  loss_labels: 1.0186 (1.0465)  loss: 0.9196 (1.0465)  time: 0.7188\n",
      "Epoch: [0]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.9065 (0.9765)  loss: 0.8987 (0.9765)  time: 0.7367\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.8785 (0.9507)  loss: 0.8911 (0.9507)  time: 0.7312\n",
      "Epoch: [0] Total time: 0:03:20 (0.7239 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.8785 (0.9507)  loss: 0.8911 (0.9507)\n",
      "Test:  [ 0/31]  eta: 0:00:23  loss_labels: 1.0492 (1.0492)  loss: 1.0492 (1.0492)  time: 0.7426\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8396 (0.8532)  loss: 0.8403 (0.8532)  time: 0.7225\n",
      "Test: Total time: 0:00:22 (0.7255 s / it)\n",
      "Averaged stats: loss_labels: 0.8396 (0.8532)  loss: 0.8403 (0.8532)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1676.61it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1695.84it/s]\n",
      "val_perf: 0.34913153165287975\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [1]  [  0/277]  eta: 0:03:20  lr: 0.000100  loss_labels: 0.7991 (0.7991)  loss: 0.7991 (0.7991)  time: 0.7237\n",
      "Epoch: [1]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.8553 (0.8586)  loss: 0.8617 (0.8586)  time: 0.7271\n",
      "Epoch: [1]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.8419 (0.8556)  loss: 0.8212 (0.8556)  time: 0.7316\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.8209 (0.8476)  loss: 0.8189 (0.8476)  time: 0.7200\n",
      "Epoch: [1] Total time: 0:03:21 (0.7268 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.8209 (0.8476)  loss: 0.8189 (0.8476)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 1.0276 (1.0276)  loss: 1.0276 (1.0276)  time: 0.7216\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8125 (0.8256)  loss: 0.8125 (0.8256)  time: 0.7198\n",
      "Test: Total time: 0:00:22 (0.7193 s / it)\n",
      "Averaged stats: loss_labels: 0.8125 (0.8256)  loss: 0.8125 (0.8256)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1673.63it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1664.93it/s]\n",
      "val_perf: 0.4010277467277843\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.43s/it]\n",
      "Epoch: [2]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.8721 (0.8721)  loss: 0.8721 (0.8721)  time: 0.7353\n",
      "Epoch: [2]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.8096 (0.8137)  loss: 0.7991 (0.8137)  time: 0.7274\n",
      "Epoch: [2]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.8082 (0.8100)  loss: 0.8223 (0.8100)  time: 0.7298\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.8209 (0.8106)  loss: 0.8270 (0.8106)  time: 0.7231\n",
      "Epoch: [2] Total time: 0:03:21 (0.7288 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.8209 (0.8106)  loss: 0.8270 (0.8106)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9827 (0.9827)  loss: 0.9827 (0.9827)  time: 0.7235\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7724 (0.7862)  loss: 0.7775 (0.7862)  time: 0.7158\n",
      "Test: Total time: 0:00:22 (0.7175 s / it)\n",
      "Averaged stats: loss_labels: 0.7724 (0.7862)  loss: 0.7775 (0.7862)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1667.30it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1676.97it/s]\n",
      "val_perf: 0.42896621443918237\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [3]  [  0/277]  eta: 0:03:22  lr: 0.000100  loss_labels: 0.8410 (0.8410)  loss: 0.8410 (0.8410)  time: 0.7306\n",
      "Epoch: [3]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7860 (0.7890)  loss: 0.7704 (0.7890)  time: 0.7278\n",
      "Epoch: [3]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.7903 (0.7912)  loss: 0.7655 (0.7912)  time: 0.7239\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7752 (0.7895)  loss: 0.7865 (0.7895)  time: 0.7178\n",
      "Epoch: [3] Total time: 0:03:21 (0.7269 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7752 (0.7895)  loss: 0.7865 (0.7895)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9634 (0.9634)  loss: 0.9634 (0.9634)  time: 0.7201\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7646 (0.7767)  loss: 0.7713 (0.7767)  time: 0.7185\n",
      "Test: Total time: 0:00:22 (0.7190 s / it)\n",
      "Averaged stats: loss_labels: 0.7646 (0.7767)  loss: 0.7713 (0.7767)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1670.39it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1631.87it/s]\n",
      "val_perf: 0.4400734124894362\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [4]  [  0/277]  eta: 0:03:35  lr: 0.000100  loss_labels: 0.7946 (0.7946)  loss: 0.7946 (0.7946)  time: 0.7786\n",
      "Epoch: [4]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7627 (0.7696)  loss: 0.7571 (0.7696)  time: 0.7260\n",
      "Epoch: [4]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7824 (0.7761)  loss: 0.7656 (0.7761)  time: 0.7288\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7712 (0.7760)  loss: 0.7868 (0.7760)  time: 0.7193\n",
      "Epoch: [4] Total time: 0:03:21 (0.7272 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7712 (0.7760)  loss: 0.7868 (0.7760)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9627 (0.9627)  loss: 0.9627 (0.9627)  time: 0.7203\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7575 (0.7700)  loss: 0.7575 (0.7700)  time: 0.7215\n",
      "Test: Total time: 0:00:22 (0.7197 s / it)\n",
      "Averaged stats: loss_labels: 0.7575 (0.7700)  loss: 0.7575 (0.7700)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1650.85it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1669.22it/s]\n",
      "val_perf: 0.44921924585862605\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [5]  [  0/277]  eta: 0:03:19  lr: 0.000100  loss_labels: 0.7594 (0.7594)  loss: 0.7594 (0.7594)  time: 0.7193\n",
      "Epoch: [5]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7626 (0.7695)  loss: 0.7843 (0.7695)  time: 0.7309\n",
      "Epoch: [5]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7587 (0.7673)  loss: 0.7410 (0.7673)  time: 0.7248\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7418 (0.7634)  loss: 0.7267 (0.7634)  time: 0.7220\n",
      "Epoch: [5] Total time: 0:03:21 (0.7279 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7418 (0.7634)  loss: 0.7267 (0.7634)\n",
      "Test:  [ 0/31]  eta: 0:00:24  loss_labels: 0.9498 (0.9498)  loss: 0.9498 (0.9498)  time: 0.8039\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7471 (0.7599)  loss: 0.7486 (0.7599)  time: 0.7206\n",
      "Test: Total time: 0:00:22 (0.7230 s / it)\n",
      "Averaged stats: loss_labels: 0.7471 (0.7599)  loss: 0.7486 (0.7599)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1648.95it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1654.53it/s]\n",
      "val_perf: 0.4557972071654538\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.45s/it]\n",
      "Epoch: [6]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.7429 (0.7429)  loss: 0.7429 (0.7429)  time: 0.7348\n",
      "Epoch: [6]  [100/277]  eta: 0:02:12  lr: 0.000100  loss_labels: 0.7394 (0.7465)  loss: 0.7422 (0.7465)  time: 0.7294\n",
      "Epoch: [6]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7503 (0.7510)  loss: 0.7478 (0.7510)  time: 0.7314\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7478 (0.7520)  loss: 0.7400 (0.7520)  time: 0.7233\n",
      "Epoch: [6] Total time: 0:03:23 (0.7361 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7478 (0.7520)  loss: 0.7400 (0.7520)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9469 (0.9469)  loss: 0.9469 (0.9469)  time: 0.7179\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7446 (0.7594)  loss: 0.7454 (0.7594)  time: 0.7226\n",
      "Test: Total time: 0:00:22 (0.7228 s / it)\n",
      "Averaged stats: loss_labels: 0.7446 (0.7594)  loss: 0.7454 (0.7594)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1649.57it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1671.60it/s]\n",
      "val_perf: 0.45819413186248037\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.45s/it]\n",
      "Epoch: [7]  [  0/277]  eta: 0:03:22  lr: 0.000100  loss_labels: 0.7193 (0.7193)  loss: 0.7193 (0.7193)  time: 0.7311\n",
      "Epoch: [7]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7412 (0.7439)  loss: 0.7409 (0.7439)  time: 0.7278\n",
      "Epoch: [7]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.7392 (0.7422)  loss: 0.7362 (0.7422)  time: 0.7264\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7381 (0.7427)  loss: 0.7038 (0.7427)  time: 0.7162\n",
      "Epoch: [7] Total time: 0:03:21 (0.7256 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7381 (0.7427)  loss: 0.7038 (0.7427)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9395 (0.9395)  loss: 0.9395 (0.9395)  time: 0.7195\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7464 (0.7603)  loss: 0.7586 (0.7603)  time: 0.7176\n",
      "Test: Total time: 0:00:22 (0.7178 s / it)\n",
      "Averaged stats: loss_labels: 0.7464 (0.7603)  loss: 0.7586 (0.7603)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1653.18it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1656.39it/s]\n",
      "val_perf: 0.4609434385145337\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [8]  [  0/277]  eta: 0:03:21  lr: 0.000100  loss_labels: 0.7777 (0.7777)  loss: 0.7777 (0.7777)  time: 0.7265\n",
      "Epoch: [8]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7356 (0.7341)  loss: 0.7451 (0.7341)  time: 0.7283\n",
      "Epoch: [8]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.7361 (0.7354)  loss: 0.7250 (0.7354)  time: 0.7257\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7292 (0.7337)  loss: 0.7318 (0.7337)  time: 0.7361\n",
      "Epoch: [8] Total time: 0:03:21 (0.7272 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7292 (0.7337)  loss: 0.7318 (0.7337)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9410 (0.9410)  loss: 0.9410 (0.9410)  time: 0.7153\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7429 (0.7527)  loss: 0.7429 (0.7527)  time: 0.7209\n",
      "Test: Total time: 0:00:22 (0.7184 s / it)\n",
      "Averaged stats: loss_labels: 0.7429 (0.7527)  loss: 0.7429 (0.7527)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1615.31it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1610.94it/s]\n",
      "val_perf: 0.46433627430606167\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [9]  [  0/277]  eta: 0:03:19  lr: 0.000100  loss_labels: 0.8001 (0.8001)  loss: 0.8001 (0.8001)  time: 0.7207\n",
      "Epoch: [9]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7162 (0.7229)  loss: 0.7250 (0.7229)  time: 0.7299\n",
      "Epoch: [9]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7219 (0.7249)  loss: 0.7024 (0.7249)  time: 0.7258\n",
      "Epoch: [9]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7241 (0.7252)  loss: 0.7293 (0.7252)  time: 0.7177\n",
      "Epoch: [9] Total time: 0:03:21 (0.7268 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7241 (0.7252)  loss: 0.7293 (0.7252)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9483 (0.9483)  loss: 0.9483 (0.9483)  time: 0.7171\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7401 (0.7526)  loss: 0.7401 (0.7526)  time: 0.7196\n",
      "Test: Total time: 0:00:22 (0.7187 s / it)\n",
      "Averaged stats: loss_labels: 0.7401 (0.7526)  loss: 0.7401 (0.7526)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1641.06it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1651.31it/s]\n",
      "val_perf: 0.46533025122762695\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [10]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.6747 (0.6747)  loss: 0.6747 (0.6747)  time: 0.7361\n",
      "Epoch: [10]  [100/277]  eta: 0:02:11  lr: 0.000100  loss_labels: 0.7167 (0.7219)  loss: 0.7075 (0.7219)  time: 0.7226\n",
      "Epoch: [10]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7163 (0.7203)  loss: 0.7218 (0.7203)  time: 0.7271\n",
      "Epoch: [10]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.7166 (0.7183)  loss: 0.6943 (0.7183)  time: 0.7199\n",
      "Epoch: [10] Total time: 0:03:22 (0.7324 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.7166 (0.7183)  loss: 0.6943 (0.7183)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.9430 (0.9430)  loss: 0.9430 (0.9430)  time: 0.7193\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7355 (0.7484)  loss: 0.7447 (0.7484)  time: 0.7191\n",
      "Test: Total time: 0:00:22 (0.7188 s / it)\n",
      "Averaged stats: loss_labels: 0.7355 (0.7484)  loss: 0.7447 (0.7484)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1646.33it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1666.31it/s]\n",
      "val_perf: 0.46715011784968274\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [11]  [  0/277]  eta: 0:03:20  lr: 0.000100  loss_labels: 0.6513 (0.6513)  loss: 0.6513 (0.6513)  time: 0.7237\n",
      "Epoch: [11]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.7104 (0.7115)  loss: 0.6942 (0.7115)  time: 0.7277\n",
      "Epoch: [11]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.7101 (0.7086)  loss: 0.7105 (0.7086)  time: 0.7278\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'streams_inc' --save_model 1 --enc_output_layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 220\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(16, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:05:03  lr: 0.000100  loss_labels: 0.0928 (0.0928)  loss: 0.0928 (0.0928)  time: 1.0958\n",
      "Epoch: [0]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0545 (0.0563)  loss: 0.0478 (0.0563)  time: 0.7328\n",
      "Epoch: [0]  [200/277]  eta: 0:00:58  lr: 0.000100  loss_labels: 0.0469 (0.0515)  loss: 0.0452 (0.0515)  time: 0.7811\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)  time: 0.7532\n",
      "Epoch: [0] Total time: 0:03:29 (0.7566 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0509 (0.0509)  loss: 0.0509 (0.0509)  time: 0.7239\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)  time: 0.7243\n",
      "Test: Total time: 0:00:22 (0.7259 s / it)\n",
      "Averaged stats: loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1708.82it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1699.74it/s]\n",
      "val_perf: 0.026510914900150034\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [1]  [  0/277]  eta: 0:03:20  lr: 0.000100  loss_labels: 0.0398 (0.0398)  loss: 0.0398 (0.0398)  time: 0.7248\n",
      "Epoch: [1]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0433 (0.0433)  loss: 0.0439 (0.0433)  time: 0.7287\n",
      "Epoch: [1]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0422 (0.0429)  loss: 0.0414 (0.0429)  time: 0.7600\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)  time: 0.7651\n",
      "Epoch: [1] Total time: 0:03:25 (0.7429 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0494 (0.0494)  loss: 0.0494 (0.0494)  time: 0.7202\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)  time: 0.7184\n",
      "Test: Total time: 0:00:22 (0.7189 s / it)\n",
      "Averaged stats: loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1700.64it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1703.31it/s]\n",
      "val_perf: 0.027940151321163592\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [2]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0428 (0.0428)  loss: 0.0428 (0.0428)  time: 0.7366\n",
      "Epoch: [2]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0408 (0.0411)  loss: 0.0399 (0.0411)  time: 0.7268\n",
      "Epoch: [2]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0409 (0.0410)  loss: 0.0418 (0.0410)  time: 0.7326\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)  time: 0.7219\n",
      "Epoch: [2] Total time: 0:03:21 (0.7289 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7253\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)  time: 0.7213\n",
      "Test: Total time: 0:00:22 (0.7190 s / it)\n",
      "Averaged stats: loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1706.20it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1705.49it/s]\n",
      "val_perf: 0.028295141922515758\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [3]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0411 (0.0411)  loss: 0.0411 (0.0411)  time: 0.7359\n",
      "Epoch: [3]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0397 (0.0400)  loss: 0.0390 (0.0400)  time: 0.7316\n",
      "Epoch: [3]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0400 (0.0402)  loss: 0.0386 (0.0402)  time: 0.7323\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)  time: 0.7214\n",
      "Epoch: [3] Total time: 0:03:21 (0.7291 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0477 (0.0477)  loss: 0.0477 (0.0477)  time: 0.7188\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)  time: 0.7194\n",
      "Test: Total time: 0:00:22 (0.7195 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1697.53it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1678.53it/s]\n",
      "val_perf: 0.028733481985735207\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.45s/it]\n",
      "Epoch: [4]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0403 (0.0403)  loss: 0.0403 (0.0403)  time: 0.7356\n",
      "Epoch: [4]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0383 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7292\n",
      "Epoch: [4]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0402 (0.0394)  loss: 0.0387 (0.0394)  time: 0.7329\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)  time: 0.7261\n",
      "Epoch: [4] Total time: 0:03:22 (0.7301 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0469 (0.0469)  loss: 0.0469 (0.0469)  time: 0.7224\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)  time: 0.7212\n",
      "Test: Total time: 0:00:22 (0.7214 s / it)\n",
      "Averaged stats: loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1693.22it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1667.95it/s]\n",
      "val_perf: 0.0287298471962317\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [5]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0380 (0.0380)  loss: 0.0380 (0.0380)  time: 0.7482\n",
      "Epoch: [5]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0384 (0.0386)  loss: 0.0384 (0.0386)  time: 0.7264\n",
      "Epoch: [5]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0391 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7300\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)  time: 0.7216\n",
      "Epoch: [5] Total time: 0:03:21 (0.7263 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0484 (0.0484)  loss: 0.0484 (0.0484)  time: 0.7292\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)  time: 0.7210\n",
      "Test: Total time: 0:00:22 (0.7223 s / it)\n",
      "Averaged stats: loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1660.93it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1636.83it/s]\n",
      "val_perf: 0.028914884954650347\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [6]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0430 (0.0430)  loss: 0.0430 (0.0430)  time: 0.7356\n",
      "Epoch: [6]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0385 (0.0384)  loss: 0.0387 (0.0384)  time: 0.7294\n",
      "Epoch: [6]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0382 (0.0385)  loss: 0.0383 (0.0385)  time: 0.7574\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)  time: 0.7231\n",
      "Epoch: [6] Total time: 0:03:22 (0.7297 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0486 (0.0486)  loss: 0.0486 (0.0486)  time: 0.7201\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)  time: 0.7155\n",
      "Test: Total time: 0:00:22 (0.7153 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1691.45it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1696.56it/s]\n",
      "val_perf: 0.028816883728600057\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [7]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0407 (0.0407)  loss: 0.0407 (0.0407)  time: 0.7388\n",
      "Epoch: [7]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0375 (0.0379)  loss: 0.0375 (0.0379)  time: 0.7286\n",
      "Epoch: [7]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0374 (0.0378)  loss: 0.0364 (0.0378)  time: 0.7292\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)  time: 0.7200\n",
      "Epoch: [7] Total time: 0:03:21 (0.7270 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7259\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)  time: 0.7174\n",
      "Test: Total time: 0:00:22 (0.7167 s / it)\n",
      "Averaged stats: loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1678.18it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1681.64it/s]\n",
      "val_perf: 0.028947353625941807\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [8]  [  0/277]  eta: 0:03:19  lr: 0.000100  loss_labels: 0.0375 (0.0375)  loss: 0.0375 (0.0375)  time: 0.7220\n",
      "Epoch: [8]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0368 (0.0372)  loss: 0.0362 (0.0372)  time: 0.7327\n",
      "Epoch: [8]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0369 (0.0372)  loss: 0.0365 (0.0372)  time: 0.7341\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)  time: 0.7262\n",
      "Epoch: [8] Total time: 0:03:22 (0.7327 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0473 (0.0473)  loss: 0.0473 (0.0473)  time: 0.7194\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)  time: 0.7182\n",
      "Test: Total time: 0:00:22 (0.7200 s / it)\n",
      "Averaged stats: loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1682.49it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1683.11it/s]\n",
      "val_perf: 0.028896020936347716\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [9]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0397 (0.0397)  loss: 0.0397 (0.0397)  time: 0.7493\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 473, in <module>\n",
      "    main(0, 1, args)\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 373, in main\n",
      "    train_stats = train_one_epoch(\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/engine.py\", line 24, in train_one_epoch\n",
      "    for imgs, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/utils/utils.py\", line 240, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/datasets/nsd.py\", line 83, in __getitem__\n",
      "    img = self.transform(img)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "          ^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 166, in to_tensor\n",
      "    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 701, in __array_interface__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 771, in tobytes\n",
      "    l, s, d = e.encode(bufsize)\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'faces' --save_model 1 --enc_output_layer 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
