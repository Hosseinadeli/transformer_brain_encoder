{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/engram/nklab/hossein/recurrent_models/transformer_brain_encoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#switch to the directory where the code is\n",
    "os.chdir('/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "lh_challenge_rois_s.shape: torch.Size([24, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([24, 20544])\n",
      "lh_challenge_rois_0.sum: tensor(5350, device='cuda:0')\n",
      "lh_challenge_rois_s.shape: torch.Size([25, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([25, 20544])\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Number of model parameters: 36805564\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(50, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:06:23  lr: 0.000500  loss_labels: 1.9626 (1.9626)  loss: 1.9626 (1.9626)  time: 1.3858\n",
      "Epoch: [0]  [100/277]  eta: 0:01:53  lr: 0.000500  loss_labels: 1.0410 (1.0629)  loss: 0.9912 (1.0629)  time: 0.6924\n",
      "Epoch: [0]  [200/277]  eta: 0:00:48  lr: 0.000500  loss_labels: 0.9337 (0.9999)  loss: 0.8874 (0.9999)  time: 0.6268\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8942 (0.9690)  loss: 0.8705 (0.9690)  time: 0.6223\n",
      "Epoch: [0] Total time: 0:02:55 (0.6332 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8942 (0.9690)  loss: 0.8705 (0.9690)\n",
      "Test:  [ 0/31]  eta: 0:00:19  loss_labels: 0.8134 (0.8134)  loss: 0.8134 (0.8134)  time: 0.6240\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8611 (0.8644)  loss: 0.8611 (0.8644)  time: 0.6164\n",
      "Test: Total time: 0:00:19 (0.6192 s / it)\n",
      "Averaged stats: loss_labels: 0.8611 (0.8644)  loss: 0.8611 (0.8644)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1699.79it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1694.13it/s]\n",
      "val_perf: 0.3443739149017205\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s]\n",
      "Epoch: [1]  [  0/277]  eta: 0:03:02  lr: 0.000500  loss_labels: 0.8228 (0.8228)  loss: 0.8228 (0.8228)  time: 0.6579\n",
      "Epoch: [1]  [100/277]  eta: 0:01:49  lr: 0.000500  loss_labels: 0.8629 (0.8710)  loss: 0.8495 (0.8710)  time: 0.6158\n",
      "Epoch: [1]  [200/277]  eta: 0:00:48  lr: 0.000500  loss_labels: 0.8529 (0.8643)  loss: 0.8619 (0.8643)  time: 0.6953\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8508 (0.8612)  loss: 0.8598 (0.8612)  time: 0.6151\n",
      "Epoch: [1] Total time: 0:02:53 (0.6260 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8508 (0.8612)  loss: 0.8598 (0.8612)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.8202 (0.8202)  loss: 0.8202 (0.8202)  time: 0.6034\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8569 (0.8570)  loss: 0.8569 (0.8570)  time: 0.6148\n",
      "Test: Total time: 0:00:19 (0.6145 s / it)\n",
      "Averaged stats: loss_labels: 0.8569 (0.8570)  loss: 0.8569 (0.8570)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1712.26it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:11<00:00, 1714.21it/s]\n",
      "val_perf: 0.37675847495361625\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.60it/s]\n",
      "Epoch: [2]  [  0/277]  eta: 0:02:49  lr: 0.000500  loss_labels: 0.9150 (0.9150)  loss: 0.9150 (0.9150)  time: 0.6108\n",
      "Epoch: [2]  [100/277]  eta: 0:01:49  lr: 0.000500  loss_labels: 0.8129 (0.8248)  loss: 0.8344 (0.8248)  time: 0.6208\n",
      "Epoch: [2]  [200/277]  eta: 0:00:47  lr: 0.000500  loss_labels: 0.8282 (0.8296)  loss: 0.8274 (0.8296)  time: 0.6239\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8336 (0.8317)  loss: 0.8470 (0.8317)  time: 0.6147\n",
      "Epoch: [2] Total time: 0:02:51 (0.6197 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8336 (0.8317)  loss: 0.8470 (0.8317)\n",
      "Test:  [ 0/31]  eta: 0:00:19  loss_labels: 0.7967 (0.7967)  loss: 0.7967 (0.7967)  time: 0.6148\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8577 (0.8417)  loss: 0.8577 (0.8417)  time: 0.6367\n",
      "Test: Total time: 0:00:19 (0.6316 s / it)\n",
      "Averaged stats: loss_labels: 0.8577 (0.8417)  loss: 0.8577 (0.8417)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1705.60it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1707.43it/s]\n",
      "val_perf: 0.3880852832166649\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.68it/s]\n",
      "Epoch: [3]  [  0/277]  eta: 0:02:51  lr: 0.000250  loss_labels: 0.8644 (0.8644)  loss: 0.8644 (0.8644)  time: 0.6201\n",
      "Epoch: [3]  [100/277]  eta: 0:01:49  lr: 0.000250  loss_labels: 0.8040 (0.8101)  loss: 0.7947 (0.8101)  time: 0.6176\n",
      "Epoch: [3]  [200/277]  eta: 0:00:47  lr: 0.000250  loss_labels: 0.7957 (0.8047)  loss: 0.7635 (0.8047)  time: 0.6227\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7832 (0.8005)  loss: 0.7710 (0.8005)  time: 0.6126\n",
      "Epoch: [3] Total time: 0:02:51 (0.6196 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7832 (0.8005)  loss: 0.7710 (0.8005)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7510 (0.7510)  loss: 0.7510 (0.7510)  time: 0.6116\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8118 (0.8020)  loss: 0.8141 (0.8020)  time: 0.6142\n",
      "Test: Total time: 0:00:19 (0.6150 s / it)\n",
      "Averaged stats: loss_labels: 0.8118 (0.8020)  loss: 0.8141 (0.8020)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1704.18it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1711.90it/s]\n",
      "val_perf: 0.4079332326459634\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s]\n",
      "Epoch: [4]  [  0/277]  eta: 0:02:49  lr: 0.000250  loss_labels: 0.7692 (0.7692)  loss: 0.7692 (0.7692)  time: 0.6114\n",
      "Epoch: [4]  [100/277]  eta: 0:01:49  lr: 0.000250  loss_labels: 0.7774 (0.7900)  loss: 0.8156 (0.7900)  time: 0.6184\n",
      "Epoch: [4]  [200/277]  eta: 0:00:48  lr: 0.000250  loss_labels: 0.7757 (0.7862)  loss: 0.7750 (0.7862)  time: 0.6232\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7849 (0.7879)  loss: 0.7769 (0.7879)  time: 0.6175\n",
      "Epoch: [4] Total time: 0:03:31 (0.7632 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7849 (0.7879)  loss: 0.7769 (0.7879)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7285 (0.7285)  loss: 0.7285 (0.7285)  time: 0.6046\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8001 (0.7977)  loss: 0.8001 (0.7977)  time: 0.6095\n",
      "Test: Total time: 0:00:18 (0.6080 s / it)\n",
      "Averaged stats: loss_labels: 0.8001 (0.7977)  loss: 0.8001 (0.7977)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1707.32it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1711.50it/s]\n",
      "val_perf: 0.4141377280346906\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s]\n",
      "Epoch: [5]  [  0/277]  eta: 0:02:51  lr: 0.000250  loss_labels: 0.7106 (0.7106)  loss: 0.7106 (0.7106)  time: 0.6194\n",
      "Epoch: [5]  [100/277]  eta: 0:01:48  lr: 0.000250  loss_labels: 0.7726 (0.7746)  loss: 0.7756 (0.7746)  time: 0.6180\n",
      "Epoch: [5]  [200/277]  eta: 0:00:47  lr: 0.000250  loss_labels: 0.7782 (0.7780)  loss: 0.7774 (0.7780)  time: 0.6156\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7753 (0.7797)  loss: 0.7675 (0.7797)  time: 0.6251\n",
      "Epoch: [5] Total time: 0:02:51 (0.6198 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7753 (0.7797)  loss: 0.7675 (0.7797)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7206 (0.7206)  loss: 0.7206 (0.7206)  time: 0.6053\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.8033 (0.7992)  loss: 0.8035 (0.7992)  time: 0.6196\n",
      "Test: Total time: 0:00:19 (0.6165 s / it)\n",
      "Averaged stats: loss_labels: 0.8033 (0.7992)  loss: 0.8035 (0.7992)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1705.90it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1711.80it/s]\n",
      "val_perf: 0.41754614777876264\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s]\n",
      "Epoch: [6]  [  0/277]  eta: 0:02:48  lr: 0.000125  loss_labels: 0.6925 (0.6925)  loss: 0.6925 (0.6925)  time: 0.6094\n",
      "Epoch: [6]  [100/277]  eta: 0:02:22  lr: 0.000125  loss_labels: 0.7642 (0.7670)  loss: 0.7516 (0.7670)  time: 0.6145\n",
      "Epoch: [6]  [200/277]  eta: 0:00:54  lr: 0.000125  loss_labels: 0.7571 (0.7656)  loss: 0.7681 (0.7656)  time: 0.6198\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7576 (0.7658)  loss: 0.7777 (0.7658)  time: 0.6162\n",
      "Epoch: [6] Total time: 0:03:10 (0.6879 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7576 (0.7658)  loss: 0.7777 (0.7658)\n",
      "Test:  [ 0/31]  eta: 0:00:19  loss_labels: 0.7407 (0.7407)  loss: 0.7407 (0.7407)  time: 0.6377\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7981 (0.7910)  loss: 0.8005 (0.7910)  time: 0.6125\n",
      "Test: Total time: 0:00:18 (0.6122 s / it)\n",
      "Averaged stats: loss_labels: 0.7981 (0.7910)  loss: 0.8005 (0.7910)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1698.19it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1702.98it/s]\n",
      "val_perf: 0.42159070406198074\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.69it/s]\n",
      "Epoch: [7]  [  0/277]  eta: 0:02:49  lr: 0.000125  loss_labels: 0.7398 (0.7398)  loss: 0.7398 (0.7398)  time: 0.6116\n",
      "Epoch: [7]  [100/277]  eta: 0:01:48  lr: 0.000125  loss_labels: 0.7514 (0.7560)  loss: 0.7522 (0.7560)  time: 0.6172\n",
      "Epoch: [7]  [200/277]  eta: 0:00:47  lr: 0.000125  loss_labels: 0.7480 (0.7564)  loss: 0.7739 (0.7564)  time: 0.6165\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7652 (0.7598)  loss: 0.7652 (0.7598)  time: 0.6157\n",
      "Epoch: [7] Total time: 0:02:50 (0.6172 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7652 (0.7598)  loss: 0.7652 (0.7598)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7083 (0.7083)  loss: 0.7083 (0.7083)  time: 0.6114\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7963 (0.7920)  loss: 0.7963 (0.7920)  time: 0.6073\n",
      "Test: Total time: 0:00:18 (0.6087 s / it)\n",
      "Averaged stats: loss_labels: 0.7963 (0.7920)  loss: 0.7963 (0.7920)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1695.68it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1667.74it/s]\n",
      "val_perf: 0.42342036395560884\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.67it/s]\n",
      "Epoch: [8]  [  0/277]  eta: 0:02:52  lr: 0.000125  loss_labels: 0.7710 (0.7710)  loss: 0.7710 (0.7710)  time: 0.6221\n",
      "Epoch: [8]  [100/277]  eta: 0:01:49  lr: 0.000125  loss_labels: 0.7370 (0.7442)  loss: 0.7319 (0.7442)  time: 0.6184\n",
      "Epoch: [8]  [200/277]  eta: 0:00:47  lr: 0.000125  loss_labels: 0.7618 (0.7520)  loss: 0.7686 (0.7520)  time: 0.6193\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000125  loss_labels: 0.7618 (0.7556)  loss: 0.7478 (0.7556)  time: 0.6174\n",
      "Epoch: [8] Total time: 0:02:52 (0.6223 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7618 (0.7556)  loss: 0.7478 (0.7556)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7150 (0.7150)  loss: 0.7150 (0.7150)  time: 0.6048\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7883 (0.7837)  loss: 0.7926 (0.7837)  time: 0.6118\n",
      "Test: Total time: 0:00:19 (0.6130 s / it)\n",
      "Averaged stats: loss_labels: 0.7883 (0.7837)  loss: 0.7926 (0.7837)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1688.07it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1690.24it/s]\n",
      "val_perf: 0.4253774974761596\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:03<00:00,  1.65it/s]\n",
      "Epoch: [9]  [  0/277]  eta: 0:02:47  lr: 0.000063  loss_labels: 0.7941 (0.7941)  loss: 0.7941 (0.7941)  time: 0.6029\n",
      "Epoch: [9]  [100/277]  eta: 0:01:50  lr: 0.000063  loss_labels: 0.7468 (0.7510)  loss: 0.7514 (0.7510)  time: 0.6285\n",
      "Epoch: [9]  [200/277]  eta: 0:00:47  lr: 0.000063  loss_labels: 0.7352 (0.7462)  loss: 0.7352 (0.7462)  time: 0.6227\n",
      "Epoch: [9]  [276/277]  eta: 0:00:00  lr: 0.000063  loss_labels: 0.7428 (0.7462)  loss: 0.7494 (0.7462)  time: 0.6117\n",
      "Epoch: [9] Total time: 0:02:52 (0.6221 s / it)\n",
      "Averaged stats: lr: 0.000063  loss_labels: 0.7428 (0.7462)  loss: 0.7494 (0.7462)\n",
      "Test:  [ 0/31]  eta: 0:00:18  loss_labels: 0.7238 (0.7238)  loss: 0.7238 (0.7238)  time: 0.6052\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7925 (0.7845)  loss: 0.7925 (0.7845)  time: 0.6116\n",
      "Test: Total time: 0:00:19 (0.6158 s / it)\n",
      "Averaged stats: loss_labels: 0.7925 (0.7845)  loss: 0.7925 (0.7845)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1706.11it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1709.15it/s]\n",
      "val_perf: 0.42477565290574865\n",
      "shape of rh_fmri_val_pred (984, 20544)\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1 #--pre_norm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n",
      "Number of model parameters: 87390140\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(2, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): resnet_model(\n",
      "      (body): IntermediateLayerGetter(\n",
      "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (bn1): FrozenBatchNorm2d()\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (layer1): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (3): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (4): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (5): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): Bottleneck(\n",
      "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): FrozenBatchNorm2d()\n",
      "            )\n",
      "          )\n",
      "          (1): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Bottleneck(\n",
      "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn1): FrozenBatchNorm2d()\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): FrozenBatchNorm2d()\n",
      "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn3): FrozenBatchNorm2d()\n",
      "            (relu): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (input_proj): AdaptiveAvgPool2d(output_size=1)\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:06:58  lr: 0.000500  loss_labels: 1.0490 (1.0490)  loss: 1.0490 (1.0490)  time: 1.5109\n",
      "Epoch: [0]  [100/277]  eta: 0:05:02  lr: 0.000500  loss_labels: 0.9121 (0.9270)  loss: 0.8982 (0.9270)  time: 1.4340\n",
      "Epoch: [0]  [200/277]  eta: 0:02:00  lr: 0.000500  loss_labels: 0.8746 (0.9021)  loss: 0.8700 (0.9021)  time: 1.3277\n",
      "Epoch: [0]  [276/277]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.8678 (0.8918)  loss: 0.8720 (0.8918)  time: 1.3875\n",
      "Epoch: [0] Total time: 0:06:58 (1.5121 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8678 (0.8918)  loss: 0.8720 (0.8918)\n",
      "Test:  [ 0/31]  eta: 0:00:39  loss_labels: 0.8433 (0.8433)  loss: 0.8433 (0.8433)  time: 1.2842\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8736 (0.8836)  loss: 0.8618 (0.8836)  time: 1.2712\n",
      "Test: Total time: 0:00:40 (1.2904 s / it)\n",
      "Averaged stats: loss_labels: 0.8736 (0.8836)  loss: 0.8618 (0.8836)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1689.61it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1684.15it/s]\n",
      "val_perf: 0.3551373694992947\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.27s/it]\n",
      "Epoch: [1]  [  0/277]  eta: 0:06:10  lr: 0.000500  loss_labels: 0.8661 (0.8661)  loss: 0.8661 (0.8661)  time: 1.3390\n",
      "Epoch: [1]  [100/277]  eta: 0:03:54  lr: 0.000500  loss_labels: 0.8448 (0.8499)  loss: 0.8284 (0.8499)  time: 1.3180\n",
      "Epoch: [1]  [200/277]  eta: 0:01:43  lr: 0.000500  loss_labels: 0.8461 (0.8509)  loss: 0.8400 (0.8509)  time: 1.3160\n",
      "Epoch: [1]  [276/277]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.8505 (0.8518)  loss: 0.8522 (0.8518)  time: 1.8430\n",
      "Epoch: [1] Total time: 0:06:25 (1.3921 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8505 (0.8518)  loss: 0.8522 (0.8518)\n",
      "Test:  [ 0/31]  eta: 0:00:49  loss_labels: 0.8340 (0.8340)  loss: 0.8340 (0.8340)  time: 1.5970\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8645 (0.8738)  loss: 0.8483 (0.8738)  time: 1.3672\n",
      "Test: Total time: 0:00:43 (1.4035 s / it)\n",
      "Averaged stats: loss_labels: 0.8645 (0.8738)  loss: 0.8483 (0.8738)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1680.54it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1680.30it/s]\n",
      "val_perf: 0.3613030762224476\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.26s/it]\n",
      "Epoch: [2]  [  0/277]  eta: 0:06:01  lr: 0.000500  loss_labels: 0.8734 (0.8734)  loss: 0.8734 (0.8734)  time: 1.3053\n",
      "Epoch: [2]  [100/277]  eta: 0:04:11  lr: 0.000500  loss_labels: 0.8435 (0.8430)  loss: 0.8576 (0.8430)  time: 1.4756\n",
      "Epoch: [2]  [200/277]  eta: 0:01:50  lr: 0.000500  loss_labels: 0.8313 (0.8400)  loss: 0.8186 (0.8400)  time: 1.4190\n",
      "Epoch: [2]  [276/277]  eta: 0:00:01  lr: 0.000500  loss_labels: 0.8373 (0.8418)  loss: 0.8420 (0.8418)  time: 1.3247\n",
      "Epoch: [2] Total time: 0:06:31 (1.4143 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8373 (0.8418)  loss: 0.8420 (0.8418)\n",
      "Test:  [ 0/31]  eta: 0:01:17  loss_labels: 0.8286 (0.8286)  loss: 0.8286 (0.8286)  time: 2.5026\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8541 (0.8641)  loss: 0.8464 (0.8641)  time: 1.3365\n",
      "Test: Total time: 0:00:44 (1.4280 s / it)\n",
      "Averaged stats: loss_labels: 0.8541 (0.8641)  loss: 0.8464 (0.8641)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1682.56it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1680.34it/s]\n",
      "val_perf: 0.36490743559444416\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.26s/it]\n",
      "Epoch: [3]  [  0/277]  eta: 0:05:49  lr: 0.000250  loss_labels: 0.8365 (0.8365)  loss: 0.8365 (0.8365)  time: 1.2623\n",
      "Epoch: [3]  [100/277]  eta: 0:03:56  lr: 0.000250  loss_labels: 0.8232 (0.8212)  loss: 0.8150 (0.8212)  time: 1.4254\n",
      "Epoch: [3]  [200/277]  eta: 0:01:46  lr: 0.000250  loss_labels: 0.8271 (0.8219)  loss: 0.8348 (0.8219)  time: 1.4688\n",
      "Epoch: [3]  [276/277]  eta: 0:00:01  lr: 0.000250  loss_labels: 0.8173 (0.8224)  loss: 0.8173 (0.8224)  time: 1.3627\n",
      "Epoch: [3] Total time: 0:06:33 (1.4205 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.8173 (0.8224)  loss: 0.8173 (0.8224)\n",
      "Test:  [ 0/31]  eta: 0:00:39  loss_labels: 0.8200 (0.8200)  loss: 0.8200 (0.8200)  time: 1.2617\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8419 (0.8567)  loss: 0.8381 (0.8567)  time: 1.2666\n",
      "Test: Total time: 0:00:40 (1.2974 s / it)\n",
      "Averaged stats: loss_labels: 0.8419 (0.8567)  loss: 0.8381 (0.8567)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1680.17it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1679.87it/s]\n",
      "val_perf: 0.36720964313379867\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.26s/it]\n",
      "Epoch: [4]  [  0/277]  eta: 0:05:52  lr: 0.000250  loss_labels: 0.8189 (0.8189)  loss: 0.8189 (0.8189)  time: 1.2708\n",
      "Epoch: [4]  [100/277]  eta: 0:04:10  lr: 0.000250  loss_labels: 0.8106 (0.8165)  loss: 0.8078 (0.8165)  time: 1.6422\n",
      "Epoch: [4]  [200/277]  eta: 0:01:53  lr: 0.000250  loss_labels: 0.8115 (0.8190)  loss: 0.8332 (0.8190)  time: 1.8231\n",
      "Epoch: [4]  [276/277]  eta: 0:00:01  lr: 0.000250  loss_labels: 0.8154 (0.8193)  loss: 0.8184 (0.8193)  time: 1.4717\n",
      "Epoch: [4] Total time: 0:06:53 (1.4914 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.8154 (0.8193)  loss: 0.8184 (0.8193)\n",
      "Test:  [ 0/31]  eta: 0:00:38  loss_labels: 0.8282 (0.8282)  loss: 0.8282 (0.8282)  time: 1.2552\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8494 (0.8565)  loss: 0.8488 (0.8565)  time: 1.3731\n",
      "Test: Total time: 0:00:43 (1.4067 s / it)\n",
      "Averaged stats: loss_labels: 0.8494 (0.8565)  loss: 0.8488 (0.8565)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1677.49it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1677.22it/s]\n",
      "val_perf: 0.368621917965145\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.27s/it]\n",
      "Epoch: [5]  [  0/277]  eta: 0:05:49  lr: 0.000250  loss_labels: 0.8007 (0.8007)  loss: 0.8007 (0.8007)  time: 1.2618\n",
      "Epoch: [5]  [100/277]  eta: 0:04:22  lr: 0.000250  loss_labels: 0.8034 (0.8168)  loss: 0.7969 (0.8168)  time: 1.2962\n",
      "Epoch: [5]  [200/277]  eta: 0:01:48  lr: 0.000250  loss_labels: 0.8180 (0.8174)  loss: 0.8142 (0.8174)  time: 1.3085\n",
      "Epoch: [5]  [276/277]  eta: 0:00:01  lr: 0.000250  loss_labels: 0.8142 (0.8174)  loss: 0.7902 (0.8174)  time: 1.2956\n",
      "Epoch: [5] Total time: 0:06:27 (1.3977 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.8142 (0.8174)  loss: 0.7902 (0.8174)\n",
      "Test:  [ 0/31]  eta: 0:00:40  loss_labels: 0.8214 (0.8214)  loss: 0.8214 (0.8214)  time: 1.2921\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8447 (0.8568)  loss: 0.8340 (0.8568)  time: 1.3202\n",
      "Test: Total time: 0:00:40 (1.3090 s / it)\n",
      "Averaged stats: loss_labels: 0.8447 (0.8568)  loss: 0.8340 (0.8568)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1678.08it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1679.87it/s]\n",
      "val_perf: 0.3675480920899221\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [6]  [  0/277]  eta: 0:05:59  lr: 0.000125  loss_labels: 0.8494 (0.8494)  loss: 0.8494 (0.8494)  time: 1.2977\n",
      "Epoch: [6]  [100/277]  eta: 0:04:00  lr: 0.000125  loss_labels: 0.8023 (0.8070)  loss: 0.7958 (0.8070)  time: 1.3231\n",
      "Epoch: [6]  [200/277]  eta: 0:01:47  lr: 0.000125  loss_labels: 0.8012 (0.8097)  loss: 0.7976 (0.8097)  time: 1.6268\n",
      "Epoch: [6]  [276/277]  eta: 0:00:01  lr: 0.000125  loss_labels: 0.7910 (0.8081)  loss: 0.7870 (0.8081)  time: 1.3241\n",
      "Epoch: [6] Total time: 0:06:25 (1.3907 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.7910 (0.8081)  loss: 0.7870 (0.8081)\n",
      "Test:  [ 0/31]  eta: 0:00:38  loss_labels: 0.8194 (0.8194)  loss: 0.8194 (0.8194)  time: 1.2544\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8396 (0.8532)  loss: 0.8346 (0.8532)  time: 1.3645\n",
      "Test: Total time: 0:00:41 (1.3341 s / it)\n",
      "Averaged stats: loss_labels: 0.8396 (0.8532)  loss: 0.8346 (0.8532)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1681.01it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1672.84it/s]\n",
      "val_perf: 0.36892909431310106\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:11<00:00,  2.30s/it]\n",
      "Epoch: [7]  [  0/277]  eta: 0:05:52  lr: 0.000125  loss_labels: 0.8049 (0.8049)  loss: 0.8049 (0.8049)  time: 1.2731\n",
      "Epoch: [7]  [100/277]  eta: 0:04:30  lr: 0.000125  loss_labels: 0.8006 (0.8019)  loss: 0.8071 (0.8019)  time: 1.8797\n",
      "Epoch: [7]  [200/277]  eta: 0:02:10  lr: 0.000125  loss_labels: 0.7991 (0.8051)  loss: 0.7921 (0.8051)  time: 1.9173\n",
      "Epoch: [7]  [276/277]  eta: 0:00:01  lr: 0.000125  loss_labels: 0.8057 (0.8064)  loss: 0.7989 (0.8064)  time: 2.3960\n",
      "Epoch: [7] Total time: 0:07:51 (1.7034 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.8057 (0.8064)  loss: 0.7989 (0.8064)\n",
      "Test:  [ 0/31]  eta: 0:00:39  loss_labels: 0.8216 (0.8216)  loss: 0.8216 (0.8216)  time: 1.2802\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8349 (0.8504)  loss: 0.8309 (0.8504)  time: 1.2884\n",
      "Test: Total time: 0:00:40 (1.2960 s / it)\n",
      "Averaged stats: loss_labels: 0.8349 (0.8504)  loss: 0.8309 (0.8504)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1682.21it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1673.65it/s]\n",
      "val_perf: 0.3695689967348728\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:06<00:00,  1.30s/it]\n",
      "Epoch: [8]  [  0/277]  eta: 0:06:12  lr: 0.000125  loss_labels: 0.7710 (0.7710)  loss: 0.7710 (0.7710)  time: 1.3444\n",
      "Epoch: [8]  [100/277]  eta: 0:04:37  lr: 0.000125  loss_labels: 0.8035 (0.8073)  loss: 0.7802 (0.8073)  time: 2.3396\n",
      "Epoch: [8]  [200/277]  eta: 0:01:59  lr: 0.000125  loss_labels: 0.8030 (0.8080)  loss: 0.8145 (0.8080)  time: 1.2825\n",
      "Epoch: [8]  [276/277]  eta: 0:00:01  lr: 0.000125  loss_labels: 0.8035 (0.8061)  loss: 0.8190 (0.8061)  time: 1.3391\n",
      "Epoch: [8] Total time: 0:06:55 (1.5001 s / it)\n",
      "Averaged stats: lr: 0.000125  loss_labels: 0.8035 (0.8061)  loss: 0.8190 (0.8061)\n",
      "Test:  [ 0/31]  eta: 0:00:39  loss_labels: 0.8217 (0.8217)  loss: 0.8217 (0.8217)  time: 1.2738\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8363 (0.8491)  loss: 0.8342 (0.8491)  time: 1.3133\n",
      "Test: Total time: 0:00:43 (1.4192 s / it)\n",
      "Averaged stats: loss_labels: 0.8363 (0.8491)  loss: 0.8342 (0.8491)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1679.89it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1677.15it/s]\n",
      "val_perf: 0.36978982476430156\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:07<00:00,  1.50s/it]\n",
      "Epoch: [9]  [  0/277]  eta: 0:05:54  lr: 0.000063  loss_labels: 0.7164 (0.7164)  loss: 0.7164 (0.7164)  time: 1.2790\n",
      "Epoch: [9]  [100/277]  eta: 0:04:31  lr: 0.000063  loss_labels: 0.7950 (0.7985)  loss: 0.7827 (0.7985)  time: 1.3907\n",
      "Epoch: [9]  [200/277]  eta: 0:01:56  lr: 0.000063  loss_labels: 0.7971 (0.7990)  loss: 0.8053 (0.7990)  time: 1.4677\n",
      "Epoch: [9]  [276/277]  eta: 0:00:01  lr: 0.000063  loss_labels: 0.8053 (0.8007)  loss: 0.7850 (0.8007)  time: 1.4216\n",
      "Epoch: [9] Total time: 0:06:53 (1.4944 s / it)\n",
      "Averaged stats: lr: 0.000063  loss_labels: 0.8053 (0.8007)  loss: 0.7850 (0.8007)\n",
      "Test:  [ 0/31]  eta: 0:00:40  loss_labels: 0.8176 (0.8176)  loss: 0.8176 (0.8176)  time: 1.2940\n",
      "Test:  [30/31]  eta: 0:00:01  loss_labels: 0.8362 (0.8471)  loss: 0.8316 (0.8471)  time: 1.3797\n",
      "Test: Total time: 0:00:41 (1.3446 s / it)\n",
      "Averaged stats: loss_labels: 0.8362 (0.8471)  loss: 0.8316 (0.8471)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1629.33it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1646.44it/s]\n",
      "val_perf: 0.37008784104239745\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:08<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'rois_all' --encoder_arch 'linear' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=12\n",
    "#SBATCH --mem-per-cpu=16G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python extract_model_features.py\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3787152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax02\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=6G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'rois_all' --save_model 1 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 2 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 3 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 4 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 6 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 7 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'rois_all' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=15\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3763573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=15\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3770662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'faces' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'bodies' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'places' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'words' --image_size 970 --backbone_arch 'resnet50' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3767741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax17\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=10G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 3 --readout_res 'voxels' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3763577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=15\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=15\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3759480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=24\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 2 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 3 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 4 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 5 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 6 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 7 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "\n",
    "python main.py --subj 1 --readout_res 'visuals' --save_model 1 --enc_output_layer 8 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'bodies' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'places' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'words' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'faces' --save_model 1 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3762458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax01\n",
    "#SBATCH --cpus-per-task=6\n",
    "#SBATCH --mem-per-cpu=8G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 2 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 3 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 4 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 5 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 6 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 7 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 8 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 11 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 12 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 9\n",
    "\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 2 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 3 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 4 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 5 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 6 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 7 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 8 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 11 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --epochs 10 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 12 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 10\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 2 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 3 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 4 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 5 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 6 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 7 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 8 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 11 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 12 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 3\n",
    "\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 --run \n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 2 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 3 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 4 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 5 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 6 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 7 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 8 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 9 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 10 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 11 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'streams_inc' --save_model 0 --enc_output_layer 12 --batch_size 32 --lr 0.0005 --lr_drop 3 --run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=16G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 7 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 8 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3780958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem-per-cpu=4G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 6 --readout_res 'voxels' --image_size 970 --backbone_arch 'resnet50' --save_model 0 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=12G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 1\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 2\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 3\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=12G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 4\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 5\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 6\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "voxel run for subject 1 for each input layer 2 through 12 (just one or 10 runs?) with dino2 backbone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=12G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 7\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 8\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3789699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax26\n",
    "#SBATCH --cpus-per-task=10\n",
    "#SBATCH --mem-per-cpu=12G\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 9\n",
    "\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 3 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 5 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 7 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 9 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "python main.py --subj 1 --readout_res 'voxels' --save_model 1 --epochs 10 --enc_output_layer 11 --batch_size 2 --lr 0.0005 --lr_drop 3 --run 10\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3526223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax17\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --wandb_p 'NSD' --wandb_r 'sub5_t_voxel_lr0005_4_g.5' --readout_res 'voxels' --save_model 1 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 4 --run 1\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 220\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(16, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:05:03  lr: 0.000100  loss_labels: 0.0928 (0.0928)  loss: 0.0928 (0.0928)  time: 1.0958\n",
      "Epoch: [0]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0545 (0.0563)  loss: 0.0478 (0.0563)  time: 0.7328\n",
      "Epoch: [0]  [200/277]  eta: 0:00:58  lr: 0.000100  loss_labels: 0.0469 (0.0515)  loss: 0.0452 (0.0515)  time: 0.7811\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)  time: 0.7532\n",
      "Epoch: [0] Total time: 0:03:29 (0.7566 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0446 (0.0495)  loss: 0.0444 (0.0495)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0509 (0.0509)  loss: 0.0509 (0.0509)  time: 0.7239\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)  time: 0.7243\n",
      "Test: Total time: 0:00:22 (0.7259 s / it)\n",
      "Averaged stats: loss_labels: 0.0426 (0.0429)  loss: 0.0426 (0.0429)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1708.82it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1699.74it/s]\n",
      "val_perf: 0.026510914900150034\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [1]  [  0/277]  eta: 0:03:20  lr: 0.000100  loss_labels: 0.0398 (0.0398)  loss: 0.0398 (0.0398)  time: 0.7248\n",
      "Epoch: [1]  [100/277]  eta: 0:02:10  lr: 0.000100  loss_labels: 0.0433 (0.0433)  loss: 0.0439 (0.0433)  time: 0.7287\n",
      "Epoch: [1]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0422 (0.0429)  loss: 0.0414 (0.0429)  time: 0.7600\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)  time: 0.7651\n",
      "Epoch: [1] Total time: 0:03:25 (0.7429 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0414 (0.0426)  loss: 0.0417 (0.0426)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0494 (0.0494)  loss: 0.0494 (0.0494)  time: 0.7202\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)  time: 0.7184\n",
      "Test: Total time: 0:00:22 (0.7189 s / it)\n",
      "Averaged stats: loss_labels: 0.0415 (0.0415)  loss: 0.0415 (0.0415)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1700.64it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1703.31it/s]\n",
      "val_perf: 0.027940151321163592\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [2]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0428 (0.0428)  loss: 0.0428 (0.0428)  time: 0.7366\n",
      "Epoch: [2]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0408 (0.0411)  loss: 0.0399 (0.0411)  time: 0.7268\n",
      "Epoch: [2]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0409 (0.0410)  loss: 0.0418 (0.0410)  time: 0.7326\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)  time: 0.7219\n",
      "Epoch: [2] Total time: 0:03:21 (0.7289 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0416 (0.0411)  loss: 0.0419 (0.0411)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7253\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)  time: 0.7213\n",
      "Test: Total time: 0:00:22 (0.7190 s / it)\n",
      "Averaged stats: loss_labels: 0.0405 (0.0407)  loss: 0.0405 (0.0407)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1706.20it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1705.49it/s]\n",
      "val_perf: 0.028295141922515758\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [3]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0411 (0.0411)  loss: 0.0411 (0.0411)  time: 0.7359\n",
      "Epoch: [3]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0397 (0.0400)  loss: 0.0390 (0.0400)  time: 0.7316\n",
      "Epoch: [3]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0400 (0.0402)  loss: 0.0386 (0.0402)  time: 0.7323\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)  time: 0.7214\n",
      "Epoch: [3] Total time: 0:03:21 (0.7291 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0398 (0.0402)  loss: 0.0409 (0.0402)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0477 (0.0477)  loss: 0.0477 (0.0477)  time: 0.7188\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)  time: 0.7194\n",
      "Test: Total time: 0:00:22 (0.7195 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0400)  loss: 0.0401 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1697.53it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1678.53it/s]\n",
      "val_perf: 0.028733481985735207\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.45s/it]\n",
      "Epoch: [4]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0403 (0.0403)  loss: 0.0403 (0.0403)  time: 0.7356\n",
      "Epoch: [4]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0383 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7292\n",
      "Epoch: [4]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0402 (0.0394)  loss: 0.0387 (0.0394)  time: 0.7329\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)  time: 0.7261\n",
      "Epoch: [4] Total time: 0:03:22 (0.7301 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0394 (0.0395)  loss: 0.0393 (0.0395)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0469 (0.0469)  loss: 0.0469 (0.0469)  time: 0.7224\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)  time: 0.7212\n",
      "Test: Total time: 0:00:22 (0.7214 s / it)\n",
      "Averaged stats: loss_labels: 0.0391 (0.0400)  loss: 0.0391 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1693.22it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1667.95it/s]\n",
      "val_perf: 0.0287298471962317\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [5]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0380 (0.0380)  loss: 0.0380 (0.0380)  time: 0.7482\n",
      "Epoch: [5]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0384 (0.0386)  loss: 0.0384 (0.0386)  time: 0.7264\n",
      "Epoch: [5]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0391 (0.0389)  loss: 0.0377 (0.0389)  time: 0.7300\n",
      "Epoch: [5]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)  time: 0.7216\n",
      "Epoch: [5] Total time: 0:03:21 (0.7263 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0383 (0.0388)  loss: 0.0388 (0.0388)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0484 (0.0484)  loss: 0.0484 (0.0484)  time: 0.7292\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)  time: 0.7210\n",
      "Test: Total time: 0:00:22 (0.7223 s / it)\n",
      "Averaged stats: loss_labels: 0.0388 (0.0400)  loss: 0.0388 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1660.93it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1636.83it/s]\n",
      "val_perf: 0.028914884954650347\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [6]  [  0/277]  eta: 0:03:23  lr: 0.000100  loss_labels: 0.0430 (0.0430)  loss: 0.0430 (0.0430)  time: 0.7356\n",
      "Epoch: [6]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0385 (0.0384)  loss: 0.0387 (0.0384)  time: 0.7294\n",
      "Epoch: [6]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0382 (0.0385)  loss: 0.0383 (0.0385)  time: 0.7574\n",
      "Epoch: [6]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)  time: 0.7231\n",
      "Epoch: [6] Total time: 0:03:22 (0.7297 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0376 (0.0383)  loss: 0.0368 (0.0383)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0486 (0.0486)  loss: 0.0486 (0.0486)  time: 0.7201\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)  time: 0.7155\n",
      "Test: Total time: 0:00:22 (0.7153 s / it)\n",
      "Averaged stats: loss_labels: 0.0401 (0.0402)  loss: 0.0401 (0.0402)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1691.45it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1696.56it/s]\n",
      "val_perf: 0.028816883728600057\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [7]  [  0/277]  eta: 0:03:24  lr: 0.000100  loss_labels: 0.0407 (0.0407)  loss: 0.0407 (0.0407)  time: 0.7388\n",
      "Epoch: [7]  [100/277]  eta: 0:02:08  lr: 0.000100  loss_labels: 0.0375 (0.0379)  loss: 0.0375 (0.0379)  time: 0.7286\n",
      "Epoch: [7]  [200/277]  eta: 0:00:55  lr: 0.000100  loss_labels: 0.0374 (0.0378)  loss: 0.0364 (0.0378)  time: 0.7292\n",
      "Epoch: [7]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)  time: 0.7200\n",
      "Epoch: [7] Total time: 0:03:21 (0.7270 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0373 (0.0378)  loss: 0.0371 (0.0378)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0487 (0.0487)  loss: 0.0487 (0.0487)  time: 0.7259\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)  time: 0.7174\n",
      "Test: Total time: 0:00:22 (0.7167 s / it)\n",
      "Averaged stats: loss_labels: 0.0402 (0.0405)  loss: 0.0402 (0.0405)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1678.18it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1681.64it/s]\n",
      "val_perf: 0.028947353625941807\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 7/7 [00:17<00:00,  2.44s/it]\n",
      "Epoch: [8]  [  0/277]  eta: 0:03:19  lr: 0.000100  loss_labels: 0.0375 (0.0375)  loss: 0.0375 (0.0375)  time: 0.7220\n",
      "Epoch: [8]  [100/277]  eta: 0:02:09  lr: 0.000100  loss_labels: 0.0368 (0.0372)  loss: 0.0362 (0.0372)  time: 0.7327\n",
      "Epoch: [8]  [200/277]  eta: 0:00:56  lr: 0.000100  loss_labels: 0.0369 (0.0372)  loss: 0.0365 (0.0372)  time: 0.7341\n",
      "Epoch: [8]  [276/277]  eta: 0:00:00  lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)  time: 0.7262\n",
      "Epoch: [8] Total time: 0:03:22 (0.7327 s / it)\n",
      "Averaged stats: lr: 0.000100  loss_labels: 0.0372 (0.0373)  loss: 0.0372 (0.0373)\n",
      "Test:  [ 0/31]  eta: 0:00:22  loss_labels: 0.0473 (0.0473)  loss: 0.0473 (0.0473)  time: 0.7194\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)  time: 0.7182\n",
      "Test: Total time: 0:00:22 (0.7200 s / it)\n",
      "Averaged stats: loss_labels: 0.0397 (0.0400)  loss: 0.0397 (0.0400)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1682.49it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1683.11it/s]\n",
      "val_perf: 0.028896020936347716\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "Epoch: [9]  [  0/277]  eta: 0:03:27  lr: 0.000100  loss_labels: 0.0397 (0.0397)  loss: 0.0397 (0.0397)  time: 0.7493\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 473, in <module>\n",
      "    main(0, 1, args)\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 373, in main\n",
      "    train_stats = train_one_epoch(\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/engine.py\", line 24, in train_one_epoch\n",
      "    for imgs, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/utils/utils.py\", line 240, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "            ~~~~~~~~~~~~^^^^^\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/datasets/nsd.py\", line 83, in __getitem__\n",
      "    img = self.transform(img)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n",
      "    img = t(img)\n",
      "          ^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/torchvision/transforms/functional.py\", line 166, in to_tensor\n",
      "    img = torch.from_numpy(np.array(pic, mode_to_nptype.get(pic.mode, np.uint8), copy=True))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 701, in __array_interface__\n",
      "    new[\"data\"] = self.tobytes()\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"/home/ha2366/.conda/envs/pytorch/lib/python3.11/site-packages/PIL/Image.py\", line 771, in tobytes\n",
      "    l, s, d = e.encode(bufsize)\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --readout_res 'faces' --save_model 1 --enc_output_layer 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39]",
   "language": "python",
   "name": "conda-env-.conda-py39-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
