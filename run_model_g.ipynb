{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/engram/nklab/hossein/recurrent_models/transformer_brain_encoder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#switch to the directory where the code is\n",
    "os.chdir('/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "lh_challenge_rois_s.shape: torch.Size([24, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([24, 20544])\n",
      "lh_challenge_rois_0.sum: tensor(5350, device='cuda:0')\n",
      "lh_challenge_rois_s.shape: torch.Size([25, 19004])\n",
      "rh_challenge_rois_s.shape: torch.Size([25, 20544])\n",
      "Training stimulus images: 8857\n",
      "Validation stimulus images: 984\n",
      "\n",
      "Test stimulus images: 159\n",
      "Using cache found in /home/ha2366/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "Number of model parameters: 36805564\n",
      "brain_encoder(\n",
      "  (transformer): Transformer(\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=768, out_features=1024, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=1024, out_features=768, bias=True)\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (memory_proj): Conv2d(768, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (query_embed): Embedding(50, 768)\n",
      "  (backbone_model): Joiner(\n",
      "    (0): dino_model_with_hooks(\n",
      "      (backbone): DinoVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
      "          (norm): Identity()\n",
      "        )\n",
      "        (blocks): ModuleList(\n",
      "          (0-11): 12 x NestedTensorBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): MemEffAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls1): LayerScale()\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (ls2): LayerScale()\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Identity()\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      "  (lh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=19004, bias=True)\n",
      "  )\n",
      "  (rh_embed): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=20544, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "train_params ['transformer.decoder.layers.0.self_attn.in_proj_weight', 'transformer.decoder.layers.0.self_attn.in_proj_bias', 'transformer.decoder.layers.0.self_attn.out_proj.weight', 'transformer.decoder.layers.0.self_attn.out_proj.bias', 'transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'transformer.decoder.layers.0.linear1.weight', 'transformer.decoder.layers.0.linear1.bias', 'transformer.decoder.layers.0.linear2.weight', 'transformer.decoder.layers.0.linear2.bias', 'transformer.decoder.layers.0.norm1.weight', 'transformer.decoder.layers.0.norm1.bias', 'transformer.decoder.layers.0.norm2.weight', 'transformer.decoder.layers.0.norm2.bias', 'transformer.decoder.layers.0.norm3.weight', 'transformer.decoder.layers.0.norm3.bias', 'transformer.decoder.norm.weight', 'transformer.decoder.norm.bias', 'transformer.memory_proj.weight', 'transformer.memory_proj.bias', 'query_embed.weight', 'lh_embed.0.weight', 'lh_embed.0.bias', 'rh_embed.0.weight', 'rh_embed.0.bias']\n",
      "Start training\n",
      "Epoch: [0]  [  0/277]  eta: 0:05:39  lr: 0.000500  loss_labels: 1.8509 (1.8509)  loss: 1.8509 (1.8509)  time: 1.2240\n",
      "Epoch: [0]  [100/277]  eta: 0:01:04  lr: 0.000500  loss_labels: 0.9540 (0.9883)  loss: 0.9046 (0.9883)  time: 0.3620\n",
      "Epoch: [0]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.8600 (0.9291)  loss: 0.8495 (0.9291)  time: 0.3610\n",
      "Epoch: [0]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.8324 (0.9023)  loss: 0.8353 (0.9023)  time: 0.3502\n",
      "Epoch: [0] Total time: 0:01:39 (0.3590 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.8324 (0.9023)  loss: 0.8353 (0.9023)\n",
      "Test:  [ 0/31]  eta: 0:00:11  loss_labels: 0.8613 (0.8613)  loss: 0.8613 (0.8613)  time: 0.3682\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7856 (0.7862)  loss: 0.7670 (0.7862)  time: 0.3533\n",
      "Test: Total time: 0:00:10 (0.3538 s / it)\n",
      "Averaged stats: loss_labels: 0.7856 (0.7862)  loss: 0.7670 (0.7862)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1591.59it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1593.40it/s]\n",
      "val_perf: 0.4298275502066601\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [1]  [  0/277]  eta: 0:01:39  lr: 0.000500  loss_labels: 0.8285 (0.8285)  loss: 0.8285 (0.8285)  time: 0.3584\n",
      "Epoch: [1]  [100/277]  eta: 0:01:04  lr: 0.000500  loss_labels: 0.7947 (0.7994)  loss: 0.7805 (0.7994)  time: 0.3510\n",
      "Epoch: [1]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.7886 (0.7982)  loss: 0.7820 (0.7982)  time: 0.3540\n",
      "Epoch: [1]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.7699 (0.7911)  loss: 0.7630 (0.7911)  time: 0.3483\n",
      "Epoch: [1] Total time: 0:01:38 (0.3565 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.7699 (0.7911)  loss: 0.7630 (0.7911)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.8247 (0.8247)  loss: 0.8247 (0.8247)  time: 0.3500\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7543 (0.7565)  loss: 0.7494 (0.7565)  time: 0.3556\n",
      "Test: Total time: 0:00:10 (0.3531 s / it)\n",
      "Averaged stats: loss_labels: 0.7543 (0.7565)  loss: 0.7494 (0.7565)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1591.77it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1602.75it/s]\n",
      "val_perf: 0.4534961461623628\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  2.19it/s]\n",
      "Epoch: [2]  [  0/277]  eta: 0:01:47  lr: 0.000500  loss_labels: 0.7970 (0.7970)  loss: 0.7970 (0.7970)  time: 0.3887\n",
      "Epoch: [2]  [100/277]  eta: 0:01:02  lr: 0.000500  loss_labels: 0.7596 (0.7618)  loss: 0.7603 (0.7618)  time: 0.3538\n",
      "Epoch: [2]  [200/277]  eta: 0:00:27  lr: 0.000500  loss_labels: 0.7559 (0.7631)  loss: 0.7835 (0.7631)  time: 0.3524\n",
      "Epoch: [2]  [276/277]  eta: 0:00:00  lr: 0.000500  loss_labels: 0.7507 (0.7591)  loss: 0.7577 (0.7591)  time: 0.3507\n",
      "Epoch: [2] Total time: 0:01:38 (0.3538 s / it)\n",
      "Averaged stats: lr: 0.000500  loss_labels: 0.7507 (0.7591)  loss: 0.7577 (0.7591)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.8059 (0.8059)  loss: 0.8059 (0.8059)  time: 0.3507\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7408 (0.7440)  loss: 0.7213 (0.7440)  time: 0.3427\n",
      "Test: Total time: 0:00:10 (0.3450 s / it)\n",
      "Averaged stats: loss_labels: 0.7408 (0.7440)  loss: 0.7213 (0.7440)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1588.23it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1600.89it/s]\n",
      "val_perf: 0.4626604151385909\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [3]  [  0/277]  eta: 0:01:38  lr: 0.000250  loss_labels: 0.7499 (0.7499)  loss: 0.7499 (0.7499)  time: 0.3555\n",
      "Epoch: [3]  [100/277]  eta: 0:01:03  lr: 0.000250  loss_labels: 0.7226 (0.7297)  loss: 0.7393 (0.7297)  time: 0.3526\n",
      "Epoch: [3]  [200/277]  eta: 0:00:27  lr: 0.000250  loss_labels: 0.7197 (0.7277)  loss: 0.7151 (0.7277)  time: 0.3526\n",
      "Epoch: [3]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7281 (0.7301)  loss: 0.7200 (0.7301)  time: 0.3481\n",
      "Epoch: [3] Total time: 0:01:38 (0.3555 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7281 (0.7301)  loss: 0.7200 (0.7301)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.7876 (0.7876)  loss: 0.7876 (0.7876)  time: 0.3485\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7296 (0.7285)  loss: 0.7149 (0.7285)  time: 0.3398\n",
      "Test: Total time: 0:00:10 (0.3423 s / it)\n",
      "Averaged stats: loss_labels: 0.7296 (0.7285)  loss: 0.7149 (0.7285)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1589.82it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1594.89it/s]\n",
      "val_perf: 0.47326889614027834\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  2.90it/s]\n",
      "Epoch: [4]  [  0/277]  eta: 0:01:36  lr: 0.000250  loss_labels: 0.7222 (0.7222)  loss: 0.7222 (0.7222)  time: 0.3487\n",
      "Epoch: [4]  [100/277]  eta: 0:01:02  lr: 0.000250  loss_labels: 0.7159 (0.7187)  loss: 0.7159 (0.7187)  time: 0.3525\n",
      "Epoch: [4]  [200/277]  eta: 0:00:27  lr: 0.000250  loss_labels: 0.7207 (0.7206)  loss: 0.7000 (0.7206)  time: 0.3504\n",
      "Epoch: [4]  [276/277]  eta: 0:00:00  lr: 0.000250  loss_labels: 0.7115 (0.7195)  loss: 0.7059 (0.7195)  time: 0.3490\n",
      "Epoch: [4] Total time: 0:01:37 (0.3535 s / it)\n",
      "Averaged stats: lr: 0.000250  loss_labels: 0.7115 (0.7195)  loss: 0.7059 (0.7195)\n",
      "Test:  [ 0/31]  eta: 0:00:10  loss_labels: 0.7896 (0.7896)  loss: 0.7896 (0.7896)  time: 0.3518\n",
      "Test:  [30/31]  eta: 0:00:00  loss_labels: 0.7305 (0.7270)  loss: 0.7056 (0.7270)  time: 0.3422\n",
      "Test: Total time: 0:00:10 (0.3441 s / it)\n",
      "Averaged stats: loss_labels: 0.7305 (0.7270)  loss: 0.7056 (0.7270)\n",
      "100%|███████████████████████████████████| 19004/19004 [00:11<00:00, 1587.32it/s]\n",
      "100%|███████████████████████████████████| 20544/20544 [00:12<00:00, 1596.28it/s]\n",
      "val_perf: 0.4753970129382543\n",
      "shape of rh_fmri_val_pred (984, 20544)\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  2.87it/s]\n",
      "Epoch: [5]  [  0/277]  eta: 0:01:37  lr: 0.000250  loss_labels: 0.6251 (0.6251)  loss: 0.6251 (0.6251)  time: 0.3534\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 534, in <module>\n",
      "    main(0, 1, args)\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/main.py\", line 430, in main\n",
      "    train_stats = train_one_epoch(\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/engine.py\", line 24, in train_one_epoch\n",
      "    for imgs, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/utils/utils.py\", line 240, in log_every\n",
      "    for obj in iterable:\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 677, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n",
      "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
      "  File \"/engram/nklab/hossein/recurrent_models/transformer_brain_encoder/datasets/nsd.py\", line 80, in __getitem__\n",
      "    img = Image.open(img_path).convert('RGB')\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/Image.py\", line 916, in convert\n",
      "    self.load()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/ImageFile.py\", line 216, in load\n",
      "    self.load_prepare()\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/PngImagePlugin.py\", line 919, in load_prepare\n",
      "    ImageFile.ImageFile.load_prepare(self)\n",
      "  File \"/home/ha2366/.conda/envs/py39/lib/python3.9/site-packages/PIL/ImageFile.py\", line 295, in load_prepare\n",
      "    self.im = Image.core.new(self.mode, self.size)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --run 15 --image_size 224 --epochs 10 --readout_res 'rois_all' --save_model 0 --enc_output_layer 1 --batch_size 32 --lr 0.0005 --lr_drop 3 #--pre_norm 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "script = f'''#!/bin/sh\n",
    "#\n",
    "#\n",
    "#SBATCH --account=nklab\n",
    "#SBATCH --job-name=vox  # The job name.\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --nodelist=ax17\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "ml load anaconda3-2019.03\n",
    "\n",
    "cd /engram/nklab/hossein/recurrent_models/transformer_brain_encoder/\n",
    "\n",
    "conda activate py39\n",
    "\n",
    "python main.py --subj 5 --wandb_p 'NSD' --wandb_r 'sub5_t_voxel_lr0005_4_g.5' --readout_res 'voxels' --save_model 1 --enc_output_layer 1 --batch_size 2 --lr 0.0005 --lr_drop 4 --run 1\n",
    "\n",
    "'''\n",
    "\n",
    "bash_script_path = \"/engram/nklab/hossein/batch_scripts/imagenet_nb.sh\"\n",
    "os.chdir('/engram/nklab/hossein/batch_scripts/')\n",
    "\n",
    "with open(bash_script_path, \"w+\") as bash_script_file:\n",
    "    bash_script_file.write(script)\n",
    "\n",
    "subprocess.run(['sbatch', '/engram/nklab/hossein/batch_scripts/imagenet_nb.sh'\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py39]",
   "language": "python",
   "name": "conda-env-.conda-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
